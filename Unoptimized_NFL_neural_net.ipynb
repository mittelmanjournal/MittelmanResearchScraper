{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mittelmanjournal/MittelmanResearchScraper/blob/main/Unoptimized_NFL_neural_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[MPG Regression for car data](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb)\n",
        "\n",
        "\n",
        "[Fashion image classification neural network](https://colab.research.google.com/github/mmphego/TensorFlow-Course/blob/master/fashion_mnist.ipynb)\n",
        "\n",
        "Above are the two Google Colab pages that I read through to understand how to create my own network."
      ],
      "metadata": {
        "id": "j7OfHyeo9Nf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import necessary libraries**\n",
        "\n",
        "This code sets up the basics for machine learning in a Google Colaboratory notebook. It imports TensorFlow, a powerful machine learning library, along with NumPy for numerical operations, Matplotlib for plotting, and Pandas for data manipulation. The last line prints the TensorFlow version, useful for checking compatibility and features. Overall, it's a starting point for machine learning tasks, ensuring the necessary tools are available."
      ],
      "metadata": {
        "id": "aersvL3cwmv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzLKpmZICaWN",
        "outputId": "ce38b7c4-02a5-44ed-ccd8-978a98c2334d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Copy the dataset into the workspace**\n",
        "and then get all of the feature/column names from the first line in the dataset.\n",
        "The class names (the different ways the neural net can \"interpret\" the input) are simply \"away win\", \"tie\", \"home win\". Then drop the first row from the dataset because these are the column names we already saved.\n",
        "<P>The first column in the dataset as we see it printed below represents the TRUE/ACTUAL output given that input, where 0 represents away win, 1 represents tie and 2 represents home win</P>\n"
      ],
      "metadata": {
        "id": "KVxxzzhdyM5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "ed67b9bc-c1eb-4ba6-fd04-3127537a0a78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      winner  seasonWeek  seasonYear  weekday  monthDay  month  year  \\\n",
              "1          2           1        2002        0         8      0  2002   \n",
              "2          2           1        2002        0         8      0  2002   \n",
              "3          0           1        2002        0         8      0  2002   \n",
              "4          2           1        2002        0         8      0  2002   \n",
              "5          0           1        2002        0         8      0  2002   \n",
              "...      ...         ...         ...      ...       ...    ...   ...   \n",
              "5228       2          19        2021        6        15      4  2022   \n",
              "5229       2          19        2021        0        16      4  2022   \n",
              "5230       0          19        2021        0        16      4  2022   \n",
              "5231       2          19        2021        0        16      4  2022   \n",
              "5232       2          19        2021        1        17      4  2022   \n",
              "\n",
              "      militaryTime  stadium  field  ...  home_K_fgm_20-29_pg  \\\n",
              "1             1304        3      0  ...             0.421384   \n",
              "2             1304        3      2  ...             0.333333   \n",
              "3             1304        3      0  ...             0.340426   \n",
              "4             1304        3      0  ...             0.441860   \n",
              "5             1304        3      0  ...             0.000000   \n",
              "...            ...      ...    ...  ...                  ...   \n",
              "5228          2015        3      3  ...             0.631579   \n",
              "5229          1300        3      0  ...             0.389474   \n",
              "5230          1640        1     -1  ...             0.405797   \n",
              "5231          2015        3      0  ...             0.500000   \n",
              "5232          2015        0     -1  ...             0.320000   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "1                0.610063             0.528302             0.503145   \n",
              "2                0.545455             0.454545             0.787879   \n",
              "3                0.404255             0.340426             0.340426   \n",
              "4                0.674419             0.593023             0.651163   \n",
              "5                0.000000             0.000000             0.000000   \n",
              "...                   ...                  ...                  ...   \n",
              "5228             0.473684             0.315789             0.631579   \n",
              "5229             0.510526             0.473684             0.600000   \n",
              "5230             0.659420             0.608696             0.550725   \n",
              "5231             0.685714             0.642857             0.585714   \n",
              "5232             0.640000             0.520000             0.880000   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "1                0.364780           0.251572           0.132075   \n",
              "2                0.575758           0.060606           0.060606   \n",
              "3                0.191489           0.000000           0.000000   \n",
              "4                0.476744           0.151163           0.069767   \n",
              "5                0.000000           0.000000           0.000000   \n",
              "...                   ...                ...                ...   \n",
              "5228             0.473684           0.473684           0.368421   \n",
              "5229             0.457895           0.210526           0.115789   \n",
              "5230             0.434783           0.485507           0.275362   \n",
              "5231             0.500000           0.300000           0.214286   \n",
              "5232             0.720000           0.360000           0.240000   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "1           52.100000       1.767296       1.723270  \n",
              "2           51.000000       1.727273       1.727273  \n",
              "3           47.333333       1.510638       1.468085  \n",
              "4           50.200000       2.546512       2.500000  \n",
              "5            0.000000       0.000000       0.000000  \n",
              "...               ...            ...            ...  \n",
              "5228        58.000000       5.684211       5.526316  \n",
              "5229        50.583333       2.489474       2.389474  \n",
              "5230        57.111111       2.572464       2.463768  \n",
              "5231        55.250000       4.028571       3.785714  \n",
              "5232        54.500000       4.520000       4.280000  \n",
              "\n",
              "[5232 rows x 702 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b93c460-e117-4b30-a8ee-0227dd11172a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.421384</td>\n",
              "      <td>0.610063</td>\n",
              "      <td>0.528302</td>\n",
              "      <td>0.503145</td>\n",
              "      <td>0.364780</td>\n",
              "      <td>0.251572</td>\n",
              "      <td>0.132075</td>\n",
              "      <td>52.100000</td>\n",
              "      <td>1.767296</td>\n",
              "      <td>1.723270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.727273</td>\n",
              "      <td>1.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.333333</td>\n",
              "      <td>1.510638</td>\n",
              "      <td>1.468085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.476744</td>\n",
              "      <td>0.151163</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>50.200000</td>\n",
              "      <td>2.546512</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.684211</td>\n",
              "      <td>5.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.457895</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>50.583333</td>\n",
              "      <td>2.489474</td>\n",
              "      <td>2.389474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1640</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.485507</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>57.111111</td>\n",
              "      <td>2.572464</td>\n",
              "      <td>2.463768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>3.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>4.280000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5232 rows × 702 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b93c460-e117-4b30-a8ee-0227dd11172a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b93c460-e117-4b30-a8ee-0227dd11172a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b93c460-e117-4b30-a8ee-0227dd11172a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c65c0a05-6dd0-4a6c-a33f-788df5fa0759\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c65c0a05-6dd0-4a6c-a33f-788df5fa0759')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c65c0a05-6dd0-4a6c-a33f-788df5fa0759 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#upload the file to this path, drag and drop dataset\n",
        "file_path = '/content/sample_data/dataset.csv'\n",
        "# Specify skiprows=1 to skip the first row (header) since we will use it as column names\n",
        "raw_dataset = pd.read_csv(file_path, na_values='?', comment='\\t',\n",
        "                          sep=',', skipinitialspace=True, skiprows=0)\n",
        "\n",
        "# The column names are automatically inferred from the header row\n",
        "column_names = raw_dataset.columns.tolist()\n",
        "class_names = ['away win','tie','home win']\n",
        "\n",
        "raw_dataset.drop(index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "oNcLBE1I3Uwl",
        "outputId": "1dd76c1d-f6f6-4380-9842-f1a27a8e8974"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      winner  seasonWeek  seasonYear  weekday  monthDay  month  year  \\\n",
              "5228       2          19        2021        6        15      4  2022   \n",
              "5229       2          19        2021        0        16      4  2022   \n",
              "5230       0          19        2021        0        16      4  2022   \n",
              "5231       2          19        2021        0        16      4  2022   \n",
              "5232       2          19        2021        1        17      4  2022   \n",
              "\n",
              "      militaryTime  stadium  field  ...  home_K_fgm_20-29_pg  \\\n",
              "5228          2015        3      3  ...             0.631579   \n",
              "5229          1300        3      0  ...             0.389474   \n",
              "5230          1640        1     -1  ...             0.405797   \n",
              "5231          2015        3      0  ...             0.500000   \n",
              "5232          2015        0     -1  ...             0.320000   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "5228             0.473684             0.315789             0.631579   \n",
              "5229             0.510526             0.473684             0.600000   \n",
              "5230             0.659420             0.608696             0.550725   \n",
              "5231             0.685714             0.642857             0.585714   \n",
              "5232             0.640000             0.520000             0.880000   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "5228             0.473684           0.473684           0.368421   \n",
              "5229             0.457895           0.210526           0.115789   \n",
              "5230             0.434783           0.485507           0.275362   \n",
              "5231             0.500000           0.300000           0.214286   \n",
              "5232             0.720000           0.360000           0.240000   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "5228        58.000000       5.684211       5.526316  \n",
              "5229        50.583333       2.489474       2.389474  \n",
              "5230        57.111111       2.572464       2.463768  \n",
              "5231        55.250000       4.028571       3.785714  \n",
              "5232        54.500000       4.520000       4.280000  \n",
              "\n",
              "[5 rows x 702 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58f6bb84-3ca8-44f7-b79d-b91d6580d022\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.684211</td>\n",
              "      <td>5.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.457895</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>50.583333</td>\n",
              "      <td>2.489474</td>\n",
              "      <td>2.389474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1640</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.485507</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>57.111111</td>\n",
              "      <td>2.572464</td>\n",
              "      <td>2.463768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>3.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>4.280000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 702 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58f6bb84-3ca8-44f7-b79d-b91d6580d022')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58f6bb84-3ca8-44f7-b79d-b91d6580d022 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58f6bb84-3ca8-44f7-b79d-b91d6580d022');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c8e98363-a95a-4921-98e6-715de64d4217\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8e98363-a95a-4921-98e6-715de64d4217')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c8e98363-a95a-4921-98e6-715de64d4217 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Drop any \"bad\" values**"
      ],
      "metadata": {
        "id": "BXCXiDlM24fK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meHViIVw3VKR",
        "outputId": "d500b44e-9757-4801-a247-fb187a152292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "winner               0\n",
              "seasonWeek           0\n",
              "seasonYear           0\n",
              "weekday              0\n",
              "monthDay             0\n",
              "                    ..\n",
              "home_K_fga_50+_pg    0\n",
              "home_K_fgm_50+_pg    0\n",
              "home_K_fglng_ps      0\n",
              "home_K_xpa_pg        0\n",
              "home_K_xpm_pg        0\n",
              "Length: 702, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6p-jbxl4jIG"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "pjFS7TbE4lep",
        "outputId": "dbdb70ce-20f4-4187-a475-e520704a39fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      winner  seasonWeek  seasonYear  weekday  monthDay  month  year  \\\n",
              "5228       2          19        2021        6        15      4  2022   \n",
              "5229       2          19        2021        0        16      4  2022   \n",
              "5230       0          19        2021        0        16      4  2022   \n",
              "5231       2          19        2021        0        16      4  2022   \n",
              "5232       2          19        2021        1        17      4  2022   \n",
              "\n",
              "      militaryTime  stadium  field  ...  home_K_fgm_20-29_pg  \\\n",
              "5228          2015        3      3  ...             0.631579   \n",
              "5229          1300        3      0  ...             0.389474   \n",
              "5230          1640        1     -1  ...             0.405797   \n",
              "5231          2015        3      0  ...             0.500000   \n",
              "5232          2015        0     -1  ...             0.320000   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "5228             0.473684             0.315789             0.631579   \n",
              "5229             0.510526             0.473684             0.600000   \n",
              "5230             0.659420             0.608696             0.550725   \n",
              "5231             0.685714             0.642857             0.585714   \n",
              "5232             0.640000             0.520000             0.880000   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "5228             0.473684           0.473684           0.368421   \n",
              "5229             0.457895           0.210526           0.115789   \n",
              "5230             0.434783           0.485507           0.275362   \n",
              "5231             0.500000           0.300000           0.214286   \n",
              "5232             0.720000           0.360000           0.240000   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "5228        58.000000       5.684211       5.526316  \n",
              "5229        50.583333       2.489474       2.389474  \n",
              "5230        57.111111       2.572464       2.463768  \n",
              "5231        55.250000       4.028571       3.785714  \n",
              "5232        54.500000       4.520000       4.280000  \n",
              "\n",
              "[5 rows x 702 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f03a08a3-4e54-45a7-b09e-76d997855e05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.684211</td>\n",
              "      <td>5.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.457895</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>50.583333</td>\n",
              "      <td>2.489474</td>\n",
              "      <td>2.389474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1640</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.485507</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>57.111111</td>\n",
              "      <td>2.572464</td>\n",
              "      <td>2.463768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>3.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>4.280000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 702 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f03a08a3-4e54-45a7-b09e-76d997855e05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f03a08a3-4e54-45a7-b09e-76d997855e05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f03a08a3-4e54-45a7-b09e-76d997855e05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-caad2567-9c7c-4b72-b4bc-ba86883729de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-caad2567-9c7c-4b72-b4bc-ba86883729de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-caad2567-9c7c-4b72-b4bc-ba86883729de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset.tail() # can also do dataset.head() to see front"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **80% of the dataset will be used for training and 20% will be used to test how well the neural net can generalize to data it hasn't seen before**"
      ],
      "metadata": {
        "id": "ERLSshJl3HBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWHtNJwP4i-l"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TP1qzu-Q6p6d",
        "outputId": "0162ae46-aaad-4bb5-d9ce-bdf8c8ae4839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    count         mean        std     min          25%  \\\n",
              "winner             4186.0     1.141185   0.989015     0.0     0.000000   \n",
              "seasonWeek         4186.0     9.342570   5.277457     1.0     5.000000   \n",
              "seasonYear         4186.0  2012.384615   6.346596  2002.0  2007.000000   \n",
              "weekday            4186.0     0.454849   1.353606     0.0     0.000000   \n",
              "monthDay           4186.0    15.794314   8.666252     1.0     9.000000   \n",
              "...                   ...          ...        ...     ...          ...   \n",
              "home_K_fga_50+_pg  4186.0     0.185284   0.134692     0.0     0.104265   \n",
              "home_K_fgm_50+_pg  4186.0     0.108272   0.090102     0.0     0.048913   \n",
              "home_K_fglng_ps    4186.0    42.153775  19.773753     0.0    46.125000   \n",
              "home_K_xpa_pg      4186.0     2.166116   1.257211     0.0     1.976870   \n",
              "home_K_xpm_pg      4186.0     2.117324   1.230122     0.0     1.939297   \n",
              "\n",
              "                           50%          75%     max  \n",
              "winner                2.000000     2.000000     2.0  \n",
              "seasonWeek            9.000000    14.000000    21.0  \n",
              "seasonYear         2012.000000  2018.000000  2023.0  \n",
              "weekday               0.000000     0.000000     6.0  \n",
              "monthDay             16.000000    23.000000    31.0  \n",
              "...                        ...          ...     ...  \n",
              "home_K_fga_50+_pg     0.178759     0.270588     2.0  \n",
              "home_K_fgm_50+_pg     0.096154     0.153846     1.0  \n",
              "home_K_fglng_ps      50.900000    53.000000    62.0  \n",
              "home_K_xpa_pg         2.333333     2.700000    20.0  \n",
              "home_K_xpm_pg         2.280710     2.636364    20.0  \n",
              "\n",
              "[702 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3874061-5740-4475-944b-e8c166b81614\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>winner</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>1.141185</td>\n",
              "      <td>0.989015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonWeek</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>9.342570</td>\n",
              "      <td>5.277457</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonYear</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>2012.384615</td>\n",
              "      <td>6.346596</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>2012.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>2023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weekday</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>0.454849</td>\n",
              "      <td>1.353606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthDay</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>15.794314</td>\n",
              "      <td>8.666252</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>0.185284</td>\n",
              "      <td>0.134692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.104265</td>\n",
              "      <td>0.178759</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>0.108272</td>\n",
              "      <td>0.090102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048913</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>42.153775</td>\n",
              "      <td>19.773753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.125000</td>\n",
              "      <td>50.900000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>2.166116</td>\n",
              "      <td>1.257211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.976870</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>2.117324</td>\n",
              "      <td>1.230122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.939297</td>\n",
              "      <td>2.280710</td>\n",
              "      <td>2.636364</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>702 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3874061-5740-4475-944b-e8c166b81614')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3874061-5740-4475-944b-e8c166b81614 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3874061-5740-4475-944b-e8c166b81614');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c806045f-4c0e-43c6-95d1-3266d9b41c41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c806045f-4c0e-43c6-95d1-3266d9b41c41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c806045f-4c0e-43c6-95d1-3266d9b41c41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_dataset.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split the data into the inputs/features and the outputs/labels of each input**\n",
        "\n",
        "for both the test and training data"
      ],
      "metadata": {
        "id": "z1rBqCFp5esj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "U5awj7rR63tp",
        "outputId": "5f3aa905-f2d7-46b8-a5c6-c5d21783530a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      seasonWeek  seasonYear  weekday  monthDay  month  year  militaryTime  \\\n",
              "3483           5        2017        0         8      1  2017          1300   \n",
              "1591          13        2008        0        30      2  2008          1302   \n",
              "3727           5        2018        0         7      1  2018          1625   \n",
              "3863          16        2018        6        22      3  2018          1630   \n",
              "1876          17        2009        0         3      4  2010          1304   \n",
              "\n",
              "      stadium  field  visSeasonWinsComingIntoGame  ...  home_K_fgm_20-29_pg  \\\n",
              "3483        3      0                            3  ...             0.000000   \n",
              "1591        3      0                            6  ...             0.407407   \n",
              "3727        3      0                            2  ...             0.388889   \n",
              "3863        3      0                            7  ...             0.378378   \n",
              "1876        3      0                           13  ...             0.460076   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "3483             0.000000             0.000000             0.000000   \n",
              "1591             0.567901             0.493827             0.506173   \n",
              "3727             0.500000             0.333333             0.833333   \n",
              "3863             0.472973             0.425676             0.628378   \n",
              "1876             0.555133             0.494297             0.524715   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "3483             0.000000           0.000000           0.000000   \n",
              "1591             0.382716           0.086420           0.024691   \n",
              "3727             0.777778           0.388889           0.333333   \n",
              "3863             0.500000           0.216216           0.114865   \n",
              "1876             0.391635           0.277567           0.144487   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "3483         0.000000       0.000000       0.000000  \n",
              "1591        50.333333       2.234568       2.197531  \n",
              "3727        61.000000       3.277778       3.000000  \n",
              "3863        52.222222       2.216216       2.162162  \n",
              "1876        50.823529       2.034221       1.988593  \n",
              "\n",
              "[5 rows x 701 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-285692f9-1be4-4e79-96c5-fe50ed72a63b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>visSeasonWinsComingIntoGame</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3483</th>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2017</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1591</th>\n",
              "      <td>13</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>1302</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.567901</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.506173</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>50.333333</td>\n",
              "      <td>2.234568</td>\n",
              "      <td>2.197531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3727</th>\n",
              "      <td>5</td>\n",
              "      <td>2018</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>1625</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>3.277778</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>16</td>\n",
              "      <td>2018</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2018</td>\n",
              "      <td>1630</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.472973</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.628378</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>52.222222</td>\n",
              "      <td>2.216216</td>\n",
              "      <td>2.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>17</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>0.460076</td>\n",
              "      <td>0.555133</td>\n",
              "      <td>0.494297</td>\n",
              "      <td>0.524715</td>\n",
              "      <td>0.391635</td>\n",
              "      <td>0.277567</td>\n",
              "      <td>0.144487</td>\n",
              "      <td>50.823529</td>\n",
              "      <td>2.034221</td>\n",
              "      <td>1.988593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 701 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-285692f9-1be4-4e79-96c5-fe50ed72a63b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-285692f9-1be4-4e79-96c5-fe50ed72a63b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-285692f9-1be4-4e79-96c5-fe50ed72a63b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41af22d4-06dc-4311-b22e-c2233c05554c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41af22d4-06dc-4311-b22e-c2233c05554c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41af22d4-06dc-4311-b22e-c2233c05554c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "train_labels = train_features.pop('winner')\n",
        "test_labels = test_features.pop('winner')\n",
        "\n",
        "train_features.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jlyMnxgS7FtK",
        "outputId": "97b24bd6-15d0-444a-c65b-944aa949f6c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          mean        std\n",
              "winner                1.141185   0.989015\n",
              "seasonWeek            9.342570   5.277457\n",
              "seasonYear         2012.384615   6.346596\n",
              "weekday               0.454849   1.353606\n",
              "monthDay             15.794314   8.666252\n",
              "...                        ...        ...\n",
              "home_K_fga_50+_pg     0.185284   0.134692\n",
              "home_K_fgm_50+_pg     0.108272   0.090102\n",
              "home_K_fglng_ps      42.153775  19.773753\n",
              "home_K_xpa_pg         2.166116   1.257211\n",
              "home_K_xpm_pg         2.117324   1.230122\n",
              "\n",
              "[702 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3d0a6a0-9187-4d91-9b2c-0a3bb5449233\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>winner</th>\n",
              "      <td>1.141185</td>\n",
              "      <td>0.989015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonWeek</th>\n",
              "      <td>9.342570</td>\n",
              "      <td>5.277457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonYear</th>\n",
              "      <td>2012.384615</td>\n",
              "      <td>6.346596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weekday</th>\n",
              "      <td>0.454849</td>\n",
              "      <td>1.353606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthDay</th>\n",
              "      <td>15.794314</td>\n",
              "      <td>8.666252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <td>0.185284</td>\n",
              "      <td>0.134692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <td>0.108272</td>\n",
              "      <td>0.090102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <td>42.153775</td>\n",
              "      <td>19.773753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <td>2.166116</td>\n",
              "      <td>1.257211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "      <td>2.117324</td>\n",
              "      <td>1.230122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>702 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3d0a6a0-9187-4d91-9b2c-0a3bb5449233')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3d0a6a0-9187-4d91-9b2c-0a3bb5449233 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3d0a6a0-9187-4d91-9b2c-0a3bb5449233');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa3d9f4f-b197-4ba4-ab77-6aecbb291dc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa3d9f4f-b197-4ba4-ab77-6aecbb291dc1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa3d9f4f-b197-4ba4-ab77-6aecbb291dc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_dataset.describe().transpose()[['mean', 'std']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalize training features**\n",
        "\n",
        "each feature/column's values are all normalized with a mean of 0 and a standard deviation of 1 (done because parameter axis=-1), read more [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization)"
      ],
      "metadata": {
        "id": "xh9PRBQI8-FL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5g0wiXA7Q3B"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8asWeQO47iRn"
      },
      "outputs": [],
      "source": [
        "normalizer.adapt(np.array(train_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTBrf8jb7vln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e201dbb2-86e1-494d-f285-bfabafd5ae3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.34256744e+00 2.01238477e+03 4.54849511e-01 1.57943153e+01\n",
            "  1.73124623e+00 2.01245288e+03 1.51749573e+03 2.32513189e+00\n",
            "  2.20950770e+00 4.43358612e+00 4.28045702e+00 2.93836631e-02\n",
            "  9.10601654e+01 5.18459091e+01 3.90379982e+01 1.76301911e-01\n",
            "  7.19213963e-01 2.74335861e-01 4.43345696e-01 5.91065502e+00\n",
            "  3.26684093e+00 2.64381242e+00 2.10099459e+00 9.75871801e-01\n",
            "  1.90942139e+02 1.01315109e+02 2.86813164e+01 5.23647881e+01\n",
            "  7.05716782e+01 3.73019600e+01 2.79049206e+01 1.20879091e-01\n",
            "  1.92661591e+01 3.15387325e+01 2.23488937e+02 1.38432479e+00\n",
            "  8.73745620e-01 8.70491886e+00 3.76401825e+01 5.45011978e+01\n",
            "  2.14167905e+00 1.39274435e+01 1.32018551e-01 3.19696164e+00\n",
            "  1.35517206e+01 1.83017895e-01 8.43762517e-01 3.47252083e+01\n",
            "  1.68324394e+01 5.33862293e-01 1.80491379e+02 9.85998764e+01\n",
            "  2.60011883e+01 2.75948353e+01 5.06925316e+01 3.33793488e+01\n",
            "  3.05817771e+00 2.26232314e+00 1.86626892e+01 7.43701458e-02\n",
            "  6.70884311e-01 4.87792740e+01 3.16250381e+01 1.30148888e+01\n",
            "  5.70791931e+01 4.14832920e-01 2.36776090e+00 5.04885063e+01\n",
            "  4.44847641e+01 1.64610803e-01 1.84540573e+02 9.93967896e+01\n",
            "  2.69226017e+01 1.91182480e+01 5.92200165e+01 3.60398865e+01\n",
            "  4.12363482e+00 2.53177667e+00 3.20332413e+01 2.04060987e-01\n",
            "  1.26183128e+00 5.23231049e+01 3.90700226e+01 8.83513987e-01\n",
            "  3.84488678e+00 4.01843376e-02 2.04333916e-01 3.18476467e+01\n",
            "  8.63869858e+00 5.71007244e-02 1.85422394e+02 9.28029175e+01\n",
            "  2.67928829e+01 2.80329647e+01 6.08626328e+01 4.33628769e+01\n",
            "  5.99454021e+00 3.52508235e+00 4.85445213e+01 3.09367239e-01\n",
            "  1.91924906e+00 5.66422081e+01 5.31081848e+01 2.11984128e-01\n",
            "  1.31175923e+00 1.27210086e-02 6.18043803e-02 3.02658558e+01\n",
            "  7.77692080e+00 6.72867894e-02 1.88450943e+02 1.00515778e+02\n",
            "  2.69006157e+01 2.28654957e+01 5.99861336e+01 4.11822701e+01\n",
            "  4.90724707e+00 2.95026660e+00 3.90858421e+01 2.57393986e-01\n",
            "  1.54613566e+00 5.58197098e+01 4.48831329e+01 1.41345128e-01\n",
            "  8.82811189e-01 1.21621639e-02 4.33503687e-02 2.25078659e+01\n",
            "  5.37318087e+00 5.64009883e-02 1.94005463e+02 1.14635902e+02\n",
            "  2.71046314e+01 1.49297647e+01 6.06664886e+01 4.17654037e+01\n",
            "  3.62975287e+00 2.33639693e+00 2.68266926e+01 2.03053400e-01\n",
            "  1.08712578e+00 5.78396950e+01 3.44122658e+01 2.18429733e-02\n",
            "  1.00912020e-01 3.88091803e-03 6.26403140e-03 5.62579298e+00\n",
            "  7.28040755e-01 3.29532772e-02 1.92804276e+02 1.27439529e+02\n",
            "  2.74421825e+01 2.64887733e+01 6.82682800e+01 4.55143127e+01\n",
            "  1.03020966e-02 1.91086275e-03 1.39039949e-01 7.23373741e-02\n",
            "  3.95816239e-03 3.11213285e-01 4.64450628e-01 1.90497899e+00\n",
            "  8.03658366e-01 4.40297276e-01 1.69713842e-03 1.91010269e+02\n",
            "  1.35699219e+02 2.74995213e+01 2.76722450e+01 6.84995041e+01\n",
            "  4.83635750e+01 7.38343410e-03 1.26038829e-03 1.20127805e-01\n",
            "  4.96555604e-02 3.56479292e-03 2.48519123e-01 4.15351331e-01\n",
            "  1.85103655e+00 8.39330614e-01 4.13353831e-01 1.15077721e-03\n",
            "  1.90905853e+02 1.37751953e+02 2.72885704e+01 2.55492077e+01\n",
            "  6.48700562e+01 4.56509590e+01 6.63542654e-03 9.43356776e-04\n",
            "  1.17303021e-01 4.18783650e-02 1.94926164e-03 2.17740312e-01\n",
            "  3.63563061e-01 1.84648168e+00 8.97047520e-01 3.91218275e-01\n",
            "  1.46226992e-03 1.91252716e+02 1.23799316e+02 2.72639694e+01\n",
            "  2.83913002e+01 6.77393799e+01 4.76997070e+01 1.58603173e-02\n",
            "  3.17839975e-03 1.60521373e-01 8.88716951e-02 4.79450496e-03\n",
            "  3.58304620e-01 4.76259083e-01 2.23832417e+00 9.11561966e-01\n",
            "  4.93944317e-01 1.98758068e-03 1.87994965e+02 1.10121826e+02\n",
            "  2.68492527e+01 2.40912457e+01 6.04331055e+01 4.25515862e+01\n",
            "  4.07059267e-02 5.78725012e-03 2.07712188e-01 6.45370781e-02\n",
            "  3.35041666e-03 1.65145248e-01 2.65761793e-01 3.37764406e+00\n",
            "  1.37224090e+00 3.72323781e-01 1.24303857e-03 1.86958603e+02\n",
            "  1.08847565e+02 2.68380280e+01 2.73392315e+01 6.21244469e+01\n",
            "  4.64457626e+01 5.23603223e-02 6.35685725e-03 2.36716181e-01\n",
            "  6.07336275e-02 3.45540862e-03 1.37652069e-01 2.14933529e-01\n",
            "  3.91049743e+00 1.59565449e+00 3.75588506e-01 1.01132994e-03\n",
            "  1.85510437e+02 1.03082428e+02 2.68282280e+01 2.61672173e+01\n",
            "  6.08213158e+01 4.57011414e+01 7.51579553e-02 8.97077285e-03\n",
            "  3.59568775e-01 6.12792410e-02 3.71878664e-03 1.25756398e-01\n",
            "  1.72041237e-01 3.53456712e+00 1.19125736e+00 3.18664491e-01\n",
            "  6.05215202e-04 1.81423553e+02 8.79326324e+01 2.66879997e+01\n",
            "  2.19591484e+01 5.93948784e+01 4.41669769e+01 1.49781853e-01\n",
            "  1.62061285e-02 6.95143938e-01 4.09622230e-02 2.89830449e-03\n",
            "  2.04405840e-02 2.71926466e-02 3.17599559e+00 6.01923347e-01\n",
            "  1.08896747e-01 2.07544392e-04 1.81684158e+02 8.83408813e+01\n",
            "  2.66101265e+01 1.95446739e+01 5.77064171e+01 3.99985657e+01\n",
            "  1.38049573e-01 1.51434531e-02 6.30015731e-01 4.40611616e-02\n",
            "  4.53423383e-03 2.52282601e-02 3.33922468e-02 3.11097836e+00\n",
            "  6.44316733e-01 1.12150326e-01 2.72242905e-04 1.83027695e+02\n",
            "  9.35485001e+01 2.69997520e+01 2.13948841e+01 6.39658127e+01\n",
            "  4.56060791e+01 1.16074570e-01 9.74090118e-03 3.87565494e-01\n",
            "  5.62325455e-02 3.08014918e-03 4.88924459e-02 7.28877112e-02\n",
            "  3.56983209e+00 1.10391784e+00 1.64295897e-01 4.54260269e-04\n",
            "  1.82671509e+02 9.19804153e+01 2.67064018e+01 2.05305729e+01\n",
            "  5.82491493e+01 4.18588104e+01 1.29536912e-01 1.04117226e-02\n",
            "  4.03264374e-01 4.73682955e-02 2.36114953e-03 3.68617587e-02\n",
            "  6.12981282e-02 3.30105209e+00 9.80823219e-01 1.27320558e-01\n",
            "  4.23837075e-04 2.97166748e+01 1.78294182e+01 9.28774261e+01\n",
            "  1.70383084e+00 1.40117133e+00 2.06669532e-02 2.04378031e-02\n",
            "  3.89481544e-01 3.73832613e-01 4.49422032e-01 3.94679278e-01\n",
            "  4.65074688e-01 3.40317219e-01 1.79992706e-01 1.05793186e-01\n",
            "  4.08029823e+01 2.07796860e+00 2.02848458e+00 4.55613899e+00\n",
            "  4.15002298e+00 2.55613867e-02 9.08444672e+01 5.15583038e+01\n",
            "  3.91180191e+01 1.68179616e-01 5.73978364e-01 1.82801530e-01\n",
            "  3.89678121e-01 5.84041882e+00 3.23005176e+00 2.61036730e+00\n",
            "  2.12147808e+00 9.77305353e-01 1.90948395e+02 1.01322731e+02\n",
            "  2.86903954e+01 5.39187737e+01 7.20976944e+01 3.85518188e+01\n",
            "  2.83655014e+01 1.18251301e-01 1.94509010e+01 3.18350468e+01\n",
            "  2.25448288e+02 1.40592062e+00 8.77223849e-01 8.77298355e+00\n",
            "  3.77629547e+01 5.45819168e+01 2.14524937e+00 1.39984741e+01\n",
            "  1.32452101e-01 3.23089385e+00 1.35907116e+01 1.86243623e-01\n",
            "  8.39883924e-01 3.46642914e+01 1.69209785e+01 5.34002721e-01\n",
            "  1.80527451e+02 9.87094879e+01 2.60162430e+01 2.74209232e+01\n",
            "  5.10528069e+01 3.32933769e+01 3.07300091e+00 2.27199268e+00\n",
            "  1.86413460e+01 7.35723823e-02 6.78389192e-01 4.91737404e+01\n",
            "  3.16159458e+01 1.30091038e+01 5.69052658e+01 4.13589805e-01\n",
            "  2.37324309e+00 5.08837814e+01 4.45831833e+01 1.65537119e-01\n",
            "  1.84448105e+02 9.89552917e+01 2.69371662e+01 1.97921562e+01\n",
            "  5.96399956e+01 3.67238350e+01 4.15856695e+00 2.54249310e+00\n",
            "  3.22416534e+01 2.06705153e-01 1.27835286e+00 5.18654404e+01\n",
            "  3.96171265e+01 9.36319232e-01 4.10908842e+00 4.26203944e-02\n",
            "  2.14672774e-01 3.23918571e+01 9.26029682e+00 5.80286868e-02\n",
            "  1.85175095e+02 9.24503098e+01 2.67718544e+01 2.74964123e+01\n",
            "  6.04758720e+01 4.23874817e+01 5.98261261e+00 3.53636551e+00\n",
            "  4.83550415e+01 3.15211087e-01 1.91471624e+00 5.72660675e+01\n",
            "  5.26715393e+01 2.40690172e-01 1.43163061e+00 1.99477151e-02\n",
            "  6.63732812e-02 3.07520237e+01 7.82328033e+00 6.85350895e-02\n",
            "  1.88524567e+02 1.00530807e+02 2.68447170e+01 2.24727612e+01\n",
            "  5.90857658e+01 3.99070892e+01 4.88124990e+00 2.93395972e+00\n",
            "  3.87179756e+01 2.60098904e-01 1.53717768e+00 5.67488251e+01\n",
            "  4.50008354e+01 1.44980490e-01 8.99968028e-01 1.69412531e-02\n",
            "  4.80880886e-02 2.25866356e+01 5.31896877e+00 5.50496541e-02\n",
            "  1.94020477e+02 1.14585754e+02 2.71020012e+01 1.48621540e+01\n",
            "  6.05604324e+01 4.15580521e+01 3.69501591e+00 2.38270831e+00\n",
            "  2.73949757e+01 2.07129225e-01 1.09722531e+00 5.74916077e+01\n",
            "  3.42138748e+01 2.53352839e-02 1.19817533e-01 6.37947069e-03\n",
            "  8.62695090e-03 5.80477524e+00 7.86501706e-01 3.36171165e-02\n",
            "  1.92907043e+02 1.27498802e+02 2.74075451e+01 2.60912571e+01\n",
            "  6.73929749e+01 4.50379906e+01 9.20246262e-03 1.96252554e-03\n",
            "  1.38596714e-01 7.20054805e-02 3.70953116e-03 3.09372187e-01\n",
            "  4.63952541e-01 1.90562832e+00 8.04076731e-01 4.38211977e-01\n",
            "  1.71735324e-03 1.91059006e+02 1.36001923e+02 2.74099445e+01\n",
            "  2.70308056e+01 6.73298721e+01 4.76258850e+01 6.94597838e-03\n",
            "  1.19525846e-03 1.18633240e-01 4.84321229e-02 3.40463663e-03\n",
            "  2.45802805e-01 4.04292464e-01 1.84046710e+00 8.41856480e-01\n",
            "  4.07691926e-01 1.30992371e-03 1.90804810e+02 1.38076157e+02\n",
            "  2.73108006e+01 2.57840366e+01 6.54813385e+01 4.58788834e+01\n",
            "  6.31094165e-03 9.26585461e-04 1.15506373e-01 4.04094942e-02\n",
            "  2.09296681e-03 2.11124286e-01 3.51783782e-01 1.81350744e+00\n",
            "  8.68736982e-01 3.85816336e-01 1.40064163e-03 1.91185898e+02\n",
            "  1.23581696e+02 2.72802200e+01 2.84663219e+01 6.75472641e+01\n",
            "  4.77914467e+01 1.60231851e-02 3.33620864e-03 1.59943968e-01\n",
            "  8.94872621e-02 4.72147670e-03 3.56770039e-01 4.73254383e-01\n",
            "  2.20363665e+00 9.02780771e-01 4.84886736e-01 2.05679541e-03\n",
            "  1.88036499e+02 1.10155258e+02 2.68203487e+01 2.38012390e+01\n",
            "  6.01206284e+01 4.24964256e+01 4.07080017e-02 5.66416280e-03\n",
            "  2.03509435e-01 6.37034103e-02 3.67132924e-03 1.63683087e-01\n",
            "  2.60856867e-01 3.33970571e+00 1.36365592e+00 3.67143810e-01\n",
            "  1.13905070e-03 1.86993530e+02 1.08807434e+02 2.68934593e+01\n",
            "  2.81134739e+01 6.30477829e+01 4.72876282e+01 5.30630015e-02\n",
            "  6.18968625e-03 2.36373156e-01 6.00426421e-02 3.62795242e-03\n",
            "  1.39288470e-01 2.14488849e-01 3.92424130e+00 1.59782052e+00\n",
            "  3.79439652e-01 9.85785155e-04 1.85620102e+02 1.03145981e+02\n",
            "  2.68609619e+01 2.59450455e+01 6.09049149e+01 4.53991776e+01\n",
            "  7.43291825e-02 8.95801745e-03 3.62421542e-01 6.34976625e-02\n",
            "  3.90778715e-03 1.30172938e-01 1.80285379e-01 3.55016780e+00\n",
            "  1.19682956e+00 3.17922384e-01 7.02810998e-04 1.81417099e+02\n",
            "  8.79235229e+01 2.67135735e+01 2.28007660e+01 6.02173882e+01\n",
            "  4.54663124e+01 1.52351782e-01 1.65249947e-02 7.03119755e-01\n",
            "  4.11283895e-02 2.76226038e-03 2.14667581e-02 2.85239071e-02\n",
            "  3.18411779e+00 6.01278543e-01 1.10938795e-01 9.52905320e-05\n",
            "  1.81652664e+02 8.84288101e+01 2.66306725e+01 1.93554630e+01\n",
            "  5.79170990e+01 3.99211464e+01 1.39863282e-01 1.53820245e-02\n",
            "  6.36650562e-01 4.53872047e-02 4.62018978e-03 2.58093942e-02\n",
            "  3.48405950e-02 3.14529157e+00 6.68132842e-01 1.15691215e-01\n",
            "  2.72874866e-04 1.83028214e+02 9.35176468e+01 2.69137611e+01\n",
            "  2.09431305e+01 6.27262192e+01 4.46693459e+01 1.19907752e-01\n",
            "  9.81983170e-03 3.95795107e-01 5.68366386e-02 3.12731951e-03\n",
            "  4.90974076e-02 7.25742206e-02 3.60702872e+00 1.09947598e+00\n",
            "  1.63479462e-01 4.15409653e-04 1.82636627e+02 9.19173584e+01\n",
            "  2.66581497e+01 2.05050068e+01 5.82613297e+01 4.18719368e+01\n",
            "  1.27404571e-01 1.08968820e-02 3.98102343e-01 4.76021729e-02\n",
            "  2.52600620e-03 3.68927903e-02 6.03209957e-02 3.28208566e+00\n",
            "  9.65649068e-01 1.26114070e-01 4.18336684e-04 2.97090263e+01\n",
            "  1.82023392e+01 9.42840271e+01 1.76177454e+00 1.44708061e+00\n",
            "  2.16129329e-02 2.13757232e-02 4.03663933e-01 3.87448072e-01\n",
            "  4.65022266e-01 4.07790214e-01 4.80964124e-01 3.51107508e-01\n",
            "  1.85284078e-01 1.08272374e-01 4.21537666e+01 2.16611743e+00\n",
            "  2.11732435e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(normalizer.mean.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBr1_tPE7xRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "5739bd34-c84c-4425-ddd0-2c52479e2511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      seasonWeek  seasonYear  weekday  monthDay  month  year  militaryTime  \\\n",
              "3483           5        2017        0         8      1  2017          1300   \n",
              "1591          13        2008        0        30      2  2008          1302   \n",
              "3727           5        2018        0         7      1  2018          1625   \n",
              "3863          16        2018        6        22      3  2018          1630   \n",
              "1876          17        2009        0         3      4  2010          1304   \n",
              "\n",
              "      stadium  field  visSeasonWinsComingIntoGame  ...  home_K_fgm_20-29_pg  \\\n",
              "3483        3      0                            3  ...             0.000000   \n",
              "1591        3      0                            6  ...             0.407407   \n",
              "3727        3      0                            2  ...             0.388889   \n",
              "3863        3      0                            7  ...             0.378378   \n",
              "1876        3      0                           13  ...             0.460076   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "3483             0.000000             0.000000             0.000000   \n",
              "1591             0.567901             0.493827             0.506173   \n",
              "3727             0.500000             0.333333             0.833333   \n",
              "3863             0.472973             0.425676             0.628378   \n",
              "1876             0.555133             0.494297             0.524715   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "3483             0.000000           0.000000           0.000000   \n",
              "1591             0.382716           0.086420           0.024691   \n",
              "3727             0.777778           0.388889           0.333333   \n",
              "3863             0.500000           0.216216           0.114865   \n",
              "1876             0.391635           0.277567           0.144487   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "3483         0.000000       0.000000       0.000000  \n",
              "1591        50.333333       2.234568       2.197531  \n",
              "3727        61.000000       3.277778       3.000000  \n",
              "3863        52.222222       2.216216       2.162162  \n",
              "1876        50.823529       2.034221       1.988593  \n",
              "\n",
              "[5 rows x 701 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8c44bd5-b1e4-4147-8bb2-c91b7359e6e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>visSeasonWinsComingIntoGame</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3483</th>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2017</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1591</th>\n",
              "      <td>13</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>1302</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.567901</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.506173</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>50.333333</td>\n",
              "      <td>2.234568</td>\n",
              "      <td>2.197531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3727</th>\n",
              "      <td>5</td>\n",
              "      <td>2018</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>1625</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>3.277778</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>16</td>\n",
              "      <td>2018</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2018</td>\n",
              "      <td>1630</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.472973</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.628378</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>52.222222</td>\n",
              "      <td>2.216216</td>\n",
              "      <td>2.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>17</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>0.460076</td>\n",
              "      <td>0.555133</td>\n",
              "      <td>0.494297</td>\n",
              "      <td>0.524715</td>\n",
              "      <td>0.391635</td>\n",
              "      <td>0.277567</td>\n",
              "      <td>0.144487</td>\n",
              "      <td>50.823529</td>\n",
              "      <td>2.034221</td>\n",
              "      <td>1.988593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 701 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c44bd5-b1e4-4147-8bb2-c91b7359e6e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8c44bd5-b1e4-4147-8bb2-c91b7359e6e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8c44bd5-b1e4-4147-8bb2-c91b7359e6e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9074462b-137a-4505-97d9-6759bdc534ec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9074462b-137a-4505-97d9-6759bdc534ec')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9074462b-137a-4505-97d9-6759bdc534ec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_features.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRFYHB2mCaWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d81a1d2-3bc2-4d8d-e8c7-1641cef2890c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4186\n",
            "4186\n"
          ]
        }
      ],
      "source": [
        "print(len(train_labels))\n",
        "print(len(train_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "Each label is an integer between 0 and 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnCTHz4CaWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3662d14-9046-42fb-a503-2dbe65f2116b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2831    0\n",
              "4377    0\n",
              "2557    2\n",
              "1977    2\n",
              "4477    2\n",
              "       ..\n",
              "3483    0\n",
              "1591    2\n",
              "3727    0\n",
              "3863    2\n",
              "1876    2\n",
              "Name: winner, Length: 4186, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJmPr5-ACaWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e9d310-21ad-4dbc-d426-e732537fbf5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1047\n",
            "1047\n"
          ]
        }
      ],
      "source": [
        "print(len(test_labels))\n",
        "print(len(test_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup neural network's layers**\n",
        "\n",
        "Arbitrary layer setup, will use hyper parameter tuning (must learn how to do this) later to try to optimize layer structure, optimization algorithm (currently using adam), loss function (currently using SparseCategoricalCrossentropy) and other hyper parameters."
      ],
      "metadata": {
        "id": "YIm36YEy-Ewe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_model(norm):\n",
        "    model = tf.keras.Sequential([\n",
        "        norm,\n",
        "        tf.keras.layers.Dense(2800, activation='relu'),\n",
        "        tf.keras.layers.Dense(1400, activation='relu'),\n",
        "        tf.keras.layers.Dense(700, activation='relu'),\n",
        "        tf.keras.layers.Dense(350, activation='relu'),\n",
        "        tf.keras.layers.Dense(100, activation='relu'),\n",
        "        tf.keras.layers.Dense(25, activation='relu'),\n",
        "        tf.keras.layers.Dense(3)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model given the input of training features, output of training labels, for 60 epochs, with a batch size of 96. Print out info given the Custom Callback class."
      ],
      "metadata": {
        "id": "8qwHVEXX_wmP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvwvpA64CaW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b61300b-3a18-47d9-c0f6-4e360091ffb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 1:42 - loss: 1.1137 - accuracy: 0.2396 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 0.9628 - accuracy: 0.3594   Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 1.8130 - accuracy: 0.3576 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 1.5432 - accuracy: 0.4167 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 1.3808 - accuracy: 0.4563 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 1.2738 - accuracy: 0.4826 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 1.1851 - accuracy: 0.5030 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 1.1207 - accuracy: 0.5208 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 1.0708 - accuracy: 0.5336 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 1.0300 - accuracy: 0.5323 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.9968 - accuracy: 0.5388 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.9672 - accuracy: 0.5469 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.9429 - accuracy: 0.5505 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.9227 - accuracy: 0.5551 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.9062 - accuracy: 0.5562 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.8880 - accuracy: 0.5599 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.8755 - accuracy: 0.5619 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.8666 - accuracy: 0.5700 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.8616 - accuracy: 0.5702 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.8496 - accuracy: 0.5771 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.8403 - accuracy: 0.5804 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.8306 - accuracy: 0.5829 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.8267 - accuracy: 0.5833 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.8249 - accuracy: 0.5859 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.8167 - accuracy: 0.5883 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.8094 - accuracy: 0.5905 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.7997 - accuracy: 0.5949 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.7925 - accuracy: 0.5971 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.7878 - accuracy: 0.5988 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.7824 - accuracy: 0.6007 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.7796 - accuracy: 0.5995 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.7761 - accuracy: 0.6006 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.7728 - accuracy: 0.6020 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.7678 - accuracy: 0.6039 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.7622 - accuracy: 0.6065 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.7560 - accuracy: 0.6091 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.7534 - accuracy: 0.6101 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.7507 - accuracy: 0.6110 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.7490 - accuracy: 0.6103 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.7452 - accuracy: 0.6125 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.7425 - accuracy: 0.6136 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.7416 - accuracy: 0.6109 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.7393 - accuracy: 0.6117 Batch 43\n",
            "44/44 [==============================] - 9s 151ms/step - loss: 0.7367 - accuracy: 0.6135\n",
            "Epoch 2/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.5126 - accuracy: 0.8125 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.5019 - accuracy: 0.8125 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.5280 - accuracy: 0.7812 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.5430 - accuracy: 0.7578 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.5476 - accuracy: 0.7375 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 0.5438 - accuracy: 0.7448 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 0.5420 - accuracy: 0.7396 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 0.5398 - accuracy: 0.7448 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 0.5346 - accuracy: 0.7454 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.5332 - accuracy: 0.7375 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.5251 - accuracy: 0.7424 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.5352 - accuracy: 0.7378 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.5431 - accuracy: 0.7348 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.5496 - accuracy: 0.7314 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.5443 - accuracy: 0.7347 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.5391 - accuracy: 0.7409 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.5347 - accuracy: 0.7451 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.5348 - accuracy: 0.7442 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.5313 - accuracy: 0.7451 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.5286 - accuracy: 0.7484 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.5287 - accuracy: 0.7465 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.5308 - accuracy: 0.7462 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.5317 - accuracy: 0.7441 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.5340 - accuracy: 0.7413 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.5314 - accuracy: 0.7429 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.5324 - accuracy: 0.7432 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.5328 - accuracy: 0.7434 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.5364 - accuracy: 0.7407 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.5350 - accuracy: 0.7417 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.5355 - accuracy: 0.7420 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.5387 - accuracy: 0.7396 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.5382 - accuracy: 0.7399 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.5385 - accuracy: 0.7386 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.5381 - accuracy: 0.7396 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.5373 - accuracy: 0.7408 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.5382 - accuracy: 0.7396 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.5363 - accuracy: 0.7418 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.5355 - accuracy: 0.7426 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.5354 - accuracy: 0.7428 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.5353 - accuracy: 0.7427 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.5360 - accuracy: 0.7419 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5354 - accuracy: 0.7413 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.7403 Batch 43\n",
            "44/44 [==============================] - 8s 188ms/step - loss: 0.5351 - accuracy: 0.7406\n",
            "Epoch 3/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.3795 - accuracy: 0.8229 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.3951 - accuracy: 0.8229 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.3631 - accuracy: 0.8542 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.3511 - accuracy: 0.8542 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.3545 - accuracy: 0.8458 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.3437 - accuracy: 0.8542 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.3367 - accuracy: 0.8571 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.3550 - accuracy: 0.8503 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.3593 - accuracy: 0.8484 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.3652 - accuracy: 0.8479 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.3599 - accuracy: 0.8513 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.3676 - accuracy: 0.8490 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.3656 - accuracy: 0.8470 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.3652 - accuracy: 0.8482 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.3656 - accuracy: 0.8472 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.3618 - accuracy: 0.8496 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.3612 - accuracy: 0.8487 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.3602 - accuracy: 0.8490 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.3596 - accuracy: 0.8503 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.3575 - accuracy: 0.8516 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.3558 - accuracy: 0.8507 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.3592 - accuracy: 0.8490 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.3564 - accuracy: 0.8510 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.3536 - accuracy: 0.8516 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.3605 - accuracy: 0.8483 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.3600 - accuracy: 0.8478 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.3603 - accuracy: 0.8472 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.3583 - accuracy: 0.8467 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.3586 - accuracy: 0.8470 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.3614 - accuracy: 0.8469 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.3616 - accuracy: 0.8464 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.3628 - accuracy: 0.8460 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.3670 - accuracy: 0.8450 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.3697 - accuracy: 0.8438 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.3715 - accuracy: 0.8417 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.3743 - accuracy: 0.8403 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.3754 - accuracy: 0.8390 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.3800 - accuracy: 0.8361 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.3817 - accuracy: 0.8355 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.3837 - accuracy: 0.8352 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.3850 - accuracy: 0.8346 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.3863 - accuracy: 0.8343 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8338 Batch 43\n",
            "44/44 [==============================] - 7s 155ms/step - loss: 0.3890 - accuracy: 0.8325\n",
            "Epoch 4/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.3099 - accuracy: 0.9062 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.2939 - accuracy: 0.8958 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.2819 - accuracy: 0.8958 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.2722 - accuracy: 0.8958 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.2622 - accuracy: 0.8979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.2625 - accuracy: 0.8993 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.2609 - accuracy: 0.8988 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.2635 - accuracy: 0.8945 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.2544 - accuracy: 0.8958 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.2612 - accuracy: 0.8938 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.2693 - accuracy: 0.8911 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.2686 - accuracy: 0.8915 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.2727 - accuracy: 0.8878 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.2694 - accuracy: 0.8891 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.2668 - accuracy: 0.8896 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.2617 - accuracy: 0.8926 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.2614 - accuracy: 0.8915 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.2660 - accuracy: 0.8900 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.2695 - accuracy: 0.8887 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.2693 - accuracy: 0.8891 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.2705 - accuracy: 0.8874 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.2739 - accuracy: 0.8859 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.2826 - accuracy: 0.8818 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.2800 - accuracy: 0.8819 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.2847 - accuracy: 0.8792 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.2865 - accuracy: 0.8798 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.2892 - accuracy: 0.8773 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.2875 - accuracy: 0.8787 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.2879 - accuracy: 0.8782 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.2915 - accuracy: 0.8757 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.2890 - accuracy: 0.8767 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.2895 - accuracy: 0.8760 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.2880 - accuracy: 0.8772 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.2888 - accuracy: 0.8768 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.2888 - accuracy: 0.8762 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.2859 - accuracy: 0.8776 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.2879 - accuracy: 0.8773 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.2878 - accuracy: 0.8777 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.2882 - accuracy: 0.8777 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.2866 - accuracy: 0.8784 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.2864 - accuracy: 0.8786 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.2857 - accuracy: 0.8797 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.2876 - accuracy: 0.8794 Batch 43\n",
            "44/44 [==============================] - 8s 174ms/step - loss: 0.2869 - accuracy: 0.8796\n",
            "Epoch 5/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.2169 - accuracy: 0.9167 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.1970 - accuracy: 0.9375 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.1834 - accuracy: 0.9410 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.1728 - accuracy: 0.9453 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.1724 - accuracy: 0.9417 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.1726 - accuracy: 0.9375 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.1773 - accuracy: 0.9315 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.1770 - accuracy: 0.9336 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.1782 - accuracy: 0.9306 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.1829 - accuracy: 0.9281 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.1835 - accuracy: 0.9280 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.1815 - accuracy: 0.9297 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.1786 - accuracy: 0.9271 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.1737 - accuracy: 0.9286 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.1694 - accuracy: 0.9312 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.1658 - accuracy: 0.9323 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.1661 - accuracy: 0.9326 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.1665 - accuracy: 0.9323 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.1641 - accuracy: 0.9342 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.1677 - accuracy: 0.9333 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.1689 - accuracy: 0.9345 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.1687 - accuracy: 0.9328 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.1742 - accuracy: 0.9312 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.1775 - accuracy: 0.9293 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.1775 - accuracy: 0.9287 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.1776 - accuracy: 0.9291 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.1759 - accuracy: 0.9294 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.1817 - accuracy: 0.9260 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.1839 - accuracy: 0.9253 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.1860 - accuracy: 0.9247 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.1886 - accuracy: 0.9244 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.1889 - accuracy: 0.9248 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.1908 - accuracy: 0.9239 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.1941 - accuracy: 0.9219 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.1934 - accuracy: 0.9217 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.1949 - accuracy: 0.9201 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.1944 - accuracy: 0.9203 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.1940 - accuracy: 0.9205 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.1949 - accuracy: 0.9199 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.1933 - accuracy: 0.9211 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.1921 - accuracy: 0.9220 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.1954 - accuracy: 0.9209 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9210 Batch 43\n",
            "44/44 [==============================] - 7s 155ms/step - loss: 0.1939 - accuracy: 0.9216\n",
            "Epoch 6/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0585 - accuracy: 0.9792 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 0.1106 - accuracy: 0.9531 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 0.1295 - accuracy: 0.9479 Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 0.1171 - accuracy: 0.9557 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 9s - loss: 0.1045 - accuracy: 0.9625 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.1051 - accuracy: 0.9618 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.1041 - accuracy: 0.9613 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 0.1049 - accuracy: 0.9622 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 0.1095 - accuracy: 0.9606 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.1157 - accuracy: 0.9594 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 0.1133 - accuracy: 0.9593 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 0.1245 - accuracy: 0.9540 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.1207 - accuracy: 0.9551 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.1258 - accuracy: 0.9516 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.1321 - accuracy: 0.9493 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 0.1311 - accuracy: 0.9499 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 0.1353 - accuracy: 0.9498 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.1381 - accuracy: 0.9479 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.1400 - accuracy: 0.9468 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 0.1433 - accuracy: 0.9453 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.1427 - accuracy: 0.9454 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.1450 - accuracy: 0.9441 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.1475 - accuracy: 0.9429 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.1514 - accuracy: 0.9414 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.1501 - accuracy: 0.9417 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.1503 - accuracy: 0.9423 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.1499 - accuracy: 0.9425 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.1483 - accuracy: 0.9435 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.1496 - accuracy: 0.9436 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.1497 - accuracy: 0.9441 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.1503 - accuracy: 0.9442 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.1510 - accuracy: 0.9437 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.1516 - accuracy: 0.9432 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.1496 - accuracy: 0.9439 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.1497 - accuracy: 0.9435 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.1523 - accuracy: 0.9436 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.1509 - accuracy: 0.9440 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.1520 - accuracy: 0.9430 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.1529 - accuracy: 0.9434 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.1543 - accuracy: 0.9427 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9418 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.1555 - accuracy: 0.9412 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9414 Batch 43\n",
            "44/44 [==============================] - 8s 187ms/step - loss: 0.1557 - accuracy: 0.9412\n",
            "Epoch 7/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0854 - accuracy: 0.9583 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0884 - accuracy: 0.9688 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.1390 - accuracy: 0.9618 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.1438 - accuracy: 0.9479 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.1329 - accuracy: 0.9479 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.1242 - accuracy: 0.9514 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.1200 - accuracy: 0.9509 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.1143 - accuracy: 0.9531 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.1197 - accuracy: 0.9514 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.1195 - accuracy: 0.9531 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.1215 - accuracy: 0.9517 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.1182 - accuracy: 0.9531 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.1157 - accuracy: 0.9543 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.1134 - accuracy: 0.9554 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.1125 - accuracy: 0.9549 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.1121 - accuracy: 0.9551 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.1116 - accuracy: 0.9559 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9560 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9550 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.1171 - accuracy: 0.9542 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.1160 - accuracy: 0.9554 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.1145 - accuracy: 0.9564 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.1117 - accuracy: 0.9574 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.1118 - accuracy: 0.9575 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.1106 - accuracy: 0.9579 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.1099 - accuracy: 0.9579 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.1118 - accuracy: 0.9579 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.1139 - accuracy: 0.9583 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.1131 - accuracy: 0.9580 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.1109 - accuracy: 0.9590 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9590 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.1120 - accuracy: 0.9587 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9593 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.1147 - accuracy: 0.9589 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.1151 - accuracy: 0.9583 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.1176 - accuracy: 0.9566 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.1164 - accuracy: 0.9575 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9559 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.1242 - accuracy: 0.9554 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.1248 - accuracy: 0.9549 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.1255 - accuracy: 0.9550 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.1274 - accuracy: 0.9541 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9537 Batch 43\n",
            "44/44 [==============================] - 7s 167ms/step - loss: 0.1279 - accuracy: 0.9534\n",
            "Epoch 8/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 11s - loss: 0.1239 - accuracy: 0.9688 Batch 1\n",
            " 2/44 [>.............................] - ETA: 11s - loss: 0.1003 - accuracy: 0.9688 Batch 2\n",
            " 3/44 [=>............................] - ETA: 10s - loss: 0.0911 - accuracy: 0.9688 Batch 3\n",
            " 4/44 [=>............................] - ETA: 10s - loss: 0.0947 - accuracy: 0.9661 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 9s - loss: 0.0893 - accuracy: 0.9708  Batch 5\n",
            " 6/44 [===>..........................] - ETA: 9s - loss: 0.0872 - accuracy: 0.9705 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0905 - accuracy: 0.9688 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 0.0934 - accuracy: 0.9688 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0875 - accuracy: 0.9711 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.0891 - accuracy: 0.9698 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0880 - accuracy: 0.9688 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0873 - accuracy: 0.9688 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0841 - accuracy: 0.9704 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0799 - accuracy: 0.9717 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0808 - accuracy: 0.9715 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0794 - accuracy: 0.9720 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0782 - accuracy: 0.9718 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0794 - accuracy: 0.9716 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0802 - accuracy: 0.9704 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0769 - accuracy: 0.9719 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0737 - accuracy: 0.9732 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0729 - accuracy: 0.9735 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0731 - accuracy: 0.9728 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0861 - accuracy: 0.9709 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0861 - accuracy: 0.9708 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0876 - accuracy: 0.9696 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0910 - accuracy: 0.9676 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0911 - accuracy: 0.9673 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0911 - accuracy: 0.9677 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0903 - accuracy: 0.9681 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0904 - accuracy: 0.9681 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0902 - accuracy: 0.9681 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0902 - accuracy: 0.9684 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0894 - accuracy: 0.9688 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0897 - accuracy: 0.9679 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0917 - accuracy: 0.9679 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0917 - accuracy: 0.9676 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0911 - accuracy: 0.9679 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0910 - accuracy: 0.9677 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0904 - accuracy: 0.9674 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0910 - accuracy: 0.9672 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0903 - accuracy: 0.9678 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9673 Batch 43\n",
            "44/44 [==============================] - 8s 171ms/step - loss: 0.0919 - accuracy: 0.9673\n",
            "Epoch 9/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0163 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 0.0166 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.0172 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0184 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0238 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0248 - accuracy: 0.9965 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0260 - accuracy: 0.9955 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0285 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0283 - accuracy: 0.9942 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0285 - accuracy: 0.9937 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0297 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0295 - accuracy: 0.9922 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0274 - accuracy: 0.9928 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0279 - accuracy: 0.9918 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0279 - accuracy: 0.9917 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0313 - accuracy: 0.9902 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0327 - accuracy: 0.9896 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0330 - accuracy: 0.9896 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0315 - accuracy: 0.9901 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0305 - accuracy: 0.9906 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0342 - accuracy: 0.9896 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0348 - accuracy: 0.9891 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0365 - accuracy: 0.9887 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0368 - accuracy: 0.9887 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0372 - accuracy: 0.9879 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0382 - accuracy: 0.9868 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0432 - accuracy: 0.9857 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0433 - accuracy: 0.9855 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0445 - accuracy: 0.9856 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0479 - accuracy: 0.9847 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0494 - accuracy: 0.9842 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0497 - accuracy: 0.9844 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0505 - accuracy: 0.9842 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0499 - accuracy: 0.9844 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0546 - accuracy: 0.9827 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0549 - accuracy: 0.9821 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0556 - accuracy: 0.9817 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0547 - accuracy: 0.9822 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0548 - accuracy: 0.9821 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0542 - accuracy: 0.9823 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0538 - accuracy: 0.9827 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0544 - accuracy: 0.9829 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9823 Batch 43\n",
            "44/44 [==============================] - 8s 190ms/step - loss: 0.0557 - accuracy: 0.9821\n",
            "Epoch 10/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0492 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0665 - accuracy: 0.9844 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0610 - accuracy: 0.9826 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0551 - accuracy: 0.9844 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0476 - accuracy: 0.9875 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0498 - accuracy: 0.9861 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0448 - accuracy: 0.9881 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0421 - accuracy: 0.9883 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0403 - accuracy: 0.9884 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0388 - accuracy: 0.9896 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0398 - accuracy: 0.9877 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0404 - accuracy: 0.9861 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0419 - accuracy: 0.9864 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0396 - accuracy: 0.9874 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0423 - accuracy: 0.9861 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0473 - accuracy: 0.9850 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0451 - accuracy: 0.9859 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0432 - accuracy: 0.9867 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0434 - accuracy: 0.9863 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0423 - accuracy: 0.9865 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0420 - accuracy: 0.9861 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0489 - accuracy: 0.9848 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0477 - accuracy: 0.9855 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0485 - accuracy: 0.9852 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0495 - accuracy: 0.9854 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0518 - accuracy: 0.9848 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0512 - accuracy: 0.9846 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0510 - accuracy: 0.9844 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0509 - accuracy: 0.9842 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0501 - accuracy: 0.9840 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0543 - accuracy: 0.9832 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0541 - accuracy: 0.9831 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0542 - accuracy: 0.9830 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0533 - accuracy: 0.9835 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0579 - accuracy: 0.9821 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0593 - accuracy: 0.9815 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0588 - accuracy: 0.9817 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0594 - accuracy: 0.9819 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0590 - accuracy: 0.9816 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0586 - accuracy: 0.9815 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0590 - accuracy: 0.9812 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0604 - accuracy: 0.9802 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9801 Batch 43\n",
            "44/44 [==============================] - 7s 159ms/step - loss: 0.0606 - accuracy: 0.9804\n",
            "Epoch 11/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.1423 - accuracy: 0.9792 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.1453 - accuracy: 0.9792 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.1180 - accuracy: 0.9792 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.0999 - accuracy: 0.9818 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0933 - accuracy: 0.9771 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 0.0973 - accuracy: 0.9740 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 0.0882 - accuracy: 0.9762 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 0.0934 - accuracy: 0.9727 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 0.0864 - accuracy: 0.9757 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0857 - accuracy: 0.9750 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0796 - accuracy: 0.9763 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0768 - accuracy: 0.9766 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0739 - accuracy: 0.9776 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0725 - accuracy: 0.9777 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0715 - accuracy: 0.9778 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0724 - accuracy: 0.9766 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0713 - accuracy: 0.9767 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0726 - accuracy: 0.9769 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.0738 - accuracy: 0.9764 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 0.0716 - accuracy: 0.9771 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 0.0742 - accuracy: 0.9757 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0762 - accuracy: 0.9744 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0755 - accuracy: 0.9751 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.0736 - accuracy: 0.9753 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 0.0712 - accuracy: 0.9762 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0695 - accuracy: 0.9768 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0685 - accuracy: 0.9769 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0667 - accuracy: 0.9777 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 0.0655 - accuracy: 0.9781 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0647 - accuracy: 0.9781 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0631 - accuracy: 0.9788 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0618 - accuracy: 0.9792 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0625 - accuracy: 0.9789 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 0.0614 - accuracy: 0.9792 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0601 - accuracy: 0.9798 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0586 - accuracy: 0.9803 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0585 - accuracy: 0.9806 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0597 - accuracy: 0.9803 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0612 - accuracy: 0.9800 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0617 - accuracy: 0.9799 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0605 - accuracy: 0.9804 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0615 - accuracy: 0.9802 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9799 Batch 43\n",
            "44/44 [==============================] - 8s 189ms/step - loss: 0.0618 - accuracy: 0.9802\n",
            "Epoch 12/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0213 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0234 - accuracy: 0.9896 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0256 - accuracy: 0.9896 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0492 - accuracy: 0.9844 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0476 - accuracy: 0.9833 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0434 - accuracy: 0.9844 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0518 - accuracy: 0.9836 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0480 - accuracy: 0.9857 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0497 - accuracy: 0.9850 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0484 - accuracy: 0.9854 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0523 - accuracy: 0.9830 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0493 - accuracy: 0.9844 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0515 - accuracy: 0.9840 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0490 - accuracy: 0.9851 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0474 - accuracy: 0.9861 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0527 - accuracy: 0.9850 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0544 - accuracy: 0.9847 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0530 - accuracy: 0.9850 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0527 - accuracy: 0.9846 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0518 - accuracy: 0.9849 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0504 - accuracy: 0.9856 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0494 - accuracy: 0.9858 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0522 - accuracy: 0.9851 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0518 - accuracy: 0.9848 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0500 - accuracy: 0.9854 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0520 - accuracy: 0.9852 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0526 - accuracy: 0.9846 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0516 - accuracy: 0.9851 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0513 - accuracy: 0.9853 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0500 - accuracy: 0.9858 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0500 - accuracy: 0.9856 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0492 - accuracy: 0.9860 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0491 - accuracy: 0.9858 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0482 - accuracy: 0.9859 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0475 - accuracy: 0.9860 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0479 - accuracy: 0.9858 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0477 - accuracy: 0.9856 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9855 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9853 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0503 - accuracy: 0.9854 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0507 - accuracy: 0.9853 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0507 - accuracy: 0.9854 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9857 Batch 43\n",
            "44/44 [==============================] - 7s 159ms/step - loss: 0.0492 - accuracy: 0.9859\n",
            "Epoch 13/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0295 - accuracy: 0.9792 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0235 - accuracy: 0.9844 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0181 - accuracy: 0.9896 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.0170 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0182 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.0195 - accuracy: 0.9913 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0173 - accuracy: 0.9926 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 0.0161 - accuracy: 0.9935 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 0.0215 - accuracy: 0.9931 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.0212 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 0.0251 - accuracy: 0.9924 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 0.0302 - accuracy: 0.9905 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 0.0336 - accuracy: 0.9896 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0379 - accuracy: 0.9881 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.0406 - accuracy: 0.9875 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 0.0421 - accuracy: 0.9863 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 0.0451 - accuracy: 0.9859 Batch 17\n",
            "18/44 [===========>..................] - ETA: 6s - loss: 0.0450 - accuracy: 0.9861 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.0535 - accuracy: 0.9852 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 0.0562 - accuracy: 0.9839 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 0.0560 - accuracy: 0.9836 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0548 - accuracy: 0.9839 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0538 - accuracy: 0.9841 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.0562 - accuracy: 0.9831 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 0.0561 - accuracy: 0.9829 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0565 - accuracy: 0.9832 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0575 - accuracy: 0.9823 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0587 - accuracy: 0.9818 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 0.0582 - accuracy: 0.9817 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0593 - accuracy: 0.9809 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0621 - accuracy: 0.9805 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0610 - accuracy: 0.9811 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0602 - accuracy: 0.9814 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 0.0655 - accuracy: 0.9801 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0656 - accuracy: 0.9801 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0650 - accuracy: 0.9800 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0648 - accuracy: 0.9803 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0651 - accuracy: 0.9803 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0648 - accuracy: 0.9800 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0653 - accuracy: 0.9797 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0646 - accuracy: 0.9799 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0658 - accuracy: 0.9799 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9801 Batch 43\n",
            "44/44 [==============================] - 8s 188ms/step - loss: 0.0649 - accuracy: 0.9802\n",
            "Epoch 14/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0159 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0129 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0159 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0259 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0220 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0292 - accuracy: 0.9931 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0286 - accuracy: 0.9926 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0435 - accuracy: 0.9909 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0410 - accuracy: 0.9919 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0386 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0372 - accuracy: 0.9924 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0364 - accuracy: 0.9922 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0381 - accuracy: 0.9912 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0437 - accuracy: 0.9881 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0413 - accuracy: 0.9889 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0395 - accuracy: 0.9896 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0375 - accuracy: 0.9902 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0370 - accuracy: 0.9902 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0355 - accuracy: 0.9907 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0357 - accuracy: 0.9901 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0351 - accuracy: 0.9901 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0346 - accuracy: 0.9901 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0356 - accuracy: 0.9891 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0344 - accuracy: 0.9896 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0339 - accuracy: 0.9896 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0357 - accuracy: 0.9884 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0424 - accuracy: 0.9873 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0441 - accuracy: 0.9859 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0463 - accuracy: 0.9856 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0492 - accuracy: 0.9851 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0485 - accuracy: 0.9852 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0478 - accuracy: 0.9854 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0474 - accuracy: 0.9855 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0470 - accuracy: 0.9856 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0465 - accuracy: 0.9854 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0464 - accuracy: 0.9852 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0455 - accuracy: 0.9856 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0453 - accuracy: 0.9855 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0454 - accuracy: 0.9850 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0459 - accuracy: 0.9846 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0456 - accuracy: 0.9848 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0454 - accuracy: 0.9849 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9852 Batch 43\n",
            "44/44 [==============================] - 7s 157ms/step - loss: 0.0440 - accuracy: 0.9854\n",
            "Epoch 15/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 0.0533 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 0.0467 - accuracy: 0.9896 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 0.0568 - accuracy: 0.9826 Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 0.0471 - accuracy: 0.9844 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0389 - accuracy: 0.9875 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.0441 - accuracy: 0.9844 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0397 - accuracy: 0.9851 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 0.0432 - accuracy: 0.9844 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 0.0416 - accuracy: 0.9838 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 0.0386 - accuracy: 0.9844 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 0.0388 - accuracy: 0.9848 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 0.0422 - accuracy: 0.9835 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0410 - accuracy: 0.9840 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0418 - accuracy: 0.9829 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.0403 - accuracy: 0.9833 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0387 - accuracy: 0.9844 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0372 - accuracy: 0.9853 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0355 - accuracy: 0.9861 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0373 - accuracy: 0.9852 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0376 - accuracy: 0.9849 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0433 - accuracy: 0.9846 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0440 - accuracy: 0.9844 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0431 - accuracy: 0.9841 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0420 - accuracy: 0.9844 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0409 - accuracy: 0.9850 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0423 - accuracy: 0.9848 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0432 - accuracy: 0.9834 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0441 - accuracy: 0.9833 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0437 - accuracy: 0.9831 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0455 - accuracy: 0.9823 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0480 - accuracy: 0.9822 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0516 - accuracy: 0.9824 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0508 - accuracy: 0.9826 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0502 - accuracy: 0.9828 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0497 - accuracy: 0.9830 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0497 - accuracy: 0.9832 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0491 - accuracy: 0.9837 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0494 - accuracy: 0.9836 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9834 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0493 - accuracy: 0.9833 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0495 - accuracy: 0.9832 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0495 - accuracy: 0.9831 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9835 Batch 43\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 0.0489 - accuracy: 0.9838\n",
            "Epoch 16/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.0263 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0207 - accuracy: 0.9896 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.0208 - accuracy: 0.9896 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.0178 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0163 - accuracy: 0.9937 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0250 - accuracy: 0.9896 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 0.0219 - accuracy: 0.9911 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 0.0196 - accuracy: 0.9922 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 0.0181 - accuracy: 0.9931 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0190 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0178 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0172 - accuracy: 0.9931 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0162 - accuracy: 0.9936 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0205 - accuracy: 0.9933 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0228 - accuracy: 0.9924 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0215 - accuracy: 0.9928 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0212 - accuracy: 0.9926 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0202 - accuracy: 0.9931 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0237 - accuracy: 0.9923 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0231 - accuracy: 0.9927 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0222 - accuracy: 0.9931 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0214 - accuracy: 0.9934 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0206 - accuracy: 0.9937 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0212 - accuracy: 0.9935 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0263 - accuracy: 0.9933 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0256 - accuracy: 0.9936 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0249 - accuracy: 0.9938 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0244 - accuracy: 0.9940 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0247 - accuracy: 0.9939 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0245 - accuracy: 0.9941 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0239 - accuracy: 0.9943 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0238 - accuracy: 0.9938 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0251 - accuracy: 0.9931 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0246 - accuracy: 0.9933 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0242 - accuracy: 0.9935 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0237 - accuracy: 0.9936 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0243 - accuracy: 0.9935 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0240 - accuracy: 0.9934 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0238 - accuracy: 0.9933 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0236 - accuracy: 0.9932 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0235 - accuracy: 0.9931 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0232 - accuracy: 0.9933 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9932 Batch 43\n",
            "44/44 [==============================] - 8s 193ms/step - loss: 0.0228 - accuracy: 0.9933\n",
            "Epoch 17/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0018 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0027 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0045 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0035 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0180 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0160 - accuracy: 0.9965 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0138 - accuracy: 0.9970 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0213 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0192 - accuracy: 0.9954 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0206 - accuracy: 0.9948 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0193 - accuracy: 0.9953 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0181 - accuracy: 0.9957 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0173 - accuracy: 0.9960 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0166 - accuracy: 0.9963 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0179 - accuracy: 0.9958 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0181 - accuracy: 0.9954 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0175 - accuracy: 0.9957 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0262 - accuracy: 0.9954 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0262 - accuracy: 0.9951 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0262 - accuracy: 0.9948 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0250 - accuracy: 0.9950 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0242 - accuracy: 0.9953 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0232 - accuracy: 0.9955 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0225 - accuracy: 0.9957 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0251 - accuracy: 0.9954 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0306 - accuracy: 0.9944 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0335 - accuracy: 0.9934 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0326 - accuracy: 0.9937 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0334 - accuracy: 0.9935 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0327 - accuracy: 0.9937 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0321 - accuracy: 0.9936 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0316 - accuracy: 0.9935 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0308 - accuracy: 0.9937 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0303 - accuracy: 0.9939 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0299 - accuracy: 0.9940 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0326 - accuracy: 0.9928 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0329 - accuracy: 0.9924 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0328 - accuracy: 0.9923 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0332 - accuracy: 0.9920 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0343 - accuracy: 0.9917 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0341 - accuracy: 0.9916 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0343 - accuracy: 0.9916 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9910 Batch 43\n",
            "44/44 [==============================] - 7s 159ms/step - loss: 0.0345 - accuracy: 0.9912\n",
            "Epoch 18/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0030 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0238 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0189 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0313 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0305 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0335 - accuracy: 0.9913 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0322 - accuracy: 0.9911 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0299 - accuracy: 0.9922 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0278 - accuracy: 0.9931 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0278 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0275 - accuracy: 0.9924 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0267 - accuracy: 0.9931 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0258 - accuracy: 0.9928 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0242 - accuracy: 0.9933 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0230 - accuracy: 0.9937 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0220 - accuracy: 0.9941 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0217 - accuracy: 0.9939 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0208 - accuracy: 0.9942 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0198 - accuracy: 0.9945 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0189 - accuracy: 0.9948 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0180 - accuracy: 0.9950 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0173 - accuracy: 0.9953 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0167 - accuracy: 0.9955 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0160 - accuracy: 0.9957 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0166 - accuracy: 0.9950 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0160 - accuracy: 0.9952 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0154 - accuracy: 0.9954 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0159 - accuracy: 0.9952 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0159 - accuracy: 0.9950 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0154 - accuracy: 0.9951 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0149 - accuracy: 0.9953 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0156 - accuracy: 0.9951 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0151 - accuracy: 0.9953 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 0.0150 - accuracy: 0.9951 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0146 - accuracy: 0.9952 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0142 - accuracy: 0.9954 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0152 - accuracy: 0.9952 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0167 - accuracy: 0.9948 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0172 - accuracy: 0.9941 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0168 - accuracy: 0.9943 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0166 - accuracy: 0.9944 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0166 - accuracy: 0.9943 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9944 Batch 43\n",
            "44/44 [==============================] - 9s 198ms/step - loss: 0.0163 - accuracy: 0.9945\n",
            "Epoch 19/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 9.3158e-04 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0112 - accuracy: 0.9948     Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.0111 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.0111 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0109 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0099 - accuracy: 0.9965 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 0.0103 - accuracy: 0.9955 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 0.0261 - accuracy: 0.9922 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 0.0244 - accuracy: 0.9931 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0237 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0328 - accuracy: 0.9924 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0369 - accuracy: 0.9905 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0367 - accuracy: 0.9904 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0406 - accuracy: 0.9896 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0382 - accuracy: 0.9903 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0393 - accuracy: 0.9896 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0378 - accuracy: 0.9902 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0369 - accuracy: 0.9902 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0362 - accuracy: 0.9907 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0371 - accuracy: 0.9896 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0373 - accuracy: 0.9896 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0366 - accuracy: 0.9901 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0359 - accuracy: 0.9900 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0367 - accuracy: 0.9896 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0364 - accuracy: 0.9892 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0365 - accuracy: 0.9884 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0367 - accuracy: 0.9880 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0364 - accuracy: 0.9881 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0381 - accuracy: 0.9878 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0390 - accuracy: 0.9875 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0385 - accuracy: 0.9872 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0374 - accuracy: 0.9876 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0394 - accuracy: 0.9877 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0384 - accuracy: 0.9881 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0375 - accuracy: 0.9884 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0368 - accuracy: 0.9887 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0370 - accuracy: 0.9882 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0368 - accuracy: 0.9882 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0360 - accuracy: 0.9885 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0364 - accuracy: 0.9880 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0359 - accuracy: 0.9881 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0357 - accuracy: 0.9881 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9884 Batch 43\n",
            "44/44 [==============================] - 8s 171ms/step - loss: 0.0354 - accuracy: 0.9883\n",
            "Epoch 20/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0022 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0082 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.0133 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.0114 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0140 - accuracy: 0.9937 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0152 - accuracy: 0.9931 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 0.0131 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 0.0115 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0103 - accuracy: 0.9954 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.0096 - accuracy: 0.9958 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 0.0088 - accuracy: 0.9962 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0086 - accuracy: 0.9965 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0103 - accuracy: 0.9960 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0147 - accuracy: 0.9948 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.0144 - accuracy: 0.9951 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 0.0145 - accuracy: 0.9948 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 0.0137 - accuracy: 0.9951 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0130 - accuracy: 0.9954 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.0133 - accuracy: 0.9951 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 0.0127 - accuracy: 0.9953 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0126 - accuracy: 0.9950 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0123 - accuracy: 0.9953 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0143 - accuracy: 0.9946 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.0138 - accuracy: 0.9948 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0135 - accuracy: 0.9950 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0137 - accuracy: 0.9944 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0168 - accuracy: 0.9938 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0165 - accuracy: 0.9940 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0170 - accuracy: 0.9939 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0166 - accuracy: 0.9941 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0166 - accuracy: 0.9940 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0162 - accuracy: 0.9941 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0159 - accuracy: 0.9943 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0165 - accuracy: 0.9942 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0164 - accuracy: 0.9940 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0169 - accuracy: 0.9939 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0169 - accuracy: 0.9938 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0165 - accuracy: 0.9940 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0161 - accuracy: 0.9941 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0166 - accuracy: 0.9940 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0170 - accuracy: 0.9939 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0169 - accuracy: 0.9938 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9939 Batch 43\n",
            "44/44 [==============================] - 8s 179ms/step - loss: 0.0165 - accuracy: 0.9940\n",
            "Epoch 21/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0010 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0201 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0164 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0177 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0151 - accuracy: 0.9937 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0131 - accuracy: 0.9948 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0170 - accuracy: 0.9926 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0161 - accuracy: 0.9935 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0174 - accuracy: 0.9931 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0159 - accuracy: 0.9937 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0164 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0177 - accuracy: 0.9922 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0164 - accuracy: 0.9928 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0165 - accuracy: 0.9926 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0181 - accuracy: 0.9924 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0181 - accuracy: 0.9922 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0172 - accuracy: 0.9926 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0175 - accuracy: 0.9925 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0176 - accuracy: 0.9923 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0180 - accuracy: 0.9922 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0175 - accuracy: 0.9926 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0170 - accuracy: 0.9929 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0165 - accuracy: 0.9932 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0166 - accuracy: 0.9935 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0160 - accuracy: 0.9937 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0155 - accuracy: 0.9940 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0152 - accuracy: 0.9942 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0148 - accuracy: 0.9944 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0153 - accuracy: 0.9943 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0155 - accuracy: 0.9941 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0192 - accuracy: 0.9936 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0197 - accuracy: 0.9932 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0192 - accuracy: 0.9934 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0187 - accuracy: 0.9936 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0183 - accuracy: 0.9937 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0178 - accuracy: 0.9939 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0174 - accuracy: 0.9941 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0187 - accuracy: 0.9934 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0186 - accuracy: 0.9933 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0183 - accuracy: 0.9935 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0182 - accuracy: 0.9934 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0185 - accuracy: 0.9933 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9935 Batch 43\n",
            "44/44 [==============================] - 8s 176ms/step - loss: 0.0182 - accuracy: 0.9935\n",
            "Epoch 22/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 0.0042 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 0.0027 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 0.0065 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 0.0191 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0192 - accuracy: 0.9937 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.0161 - accuracy: 0.9948 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0143 - accuracy: 0.9955 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 0.0127 - accuracy: 0.9961 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0120 - accuracy: 0.9965 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.0115 - accuracy: 0.9969 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 0.0106 - accuracy: 0.9972 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0100 - accuracy: 0.9974 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0120 - accuracy: 0.9960 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0167 - accuracy: 0.9940 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0156 - accuracy: 0.9944 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0167 - accuracy: 0.9941 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0159 - accuracy: 0.9945 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0182 - accuracy: 0.9931 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0174 - accuracy: 0.9934 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0166 - accuracy: 0.9937 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0163 - accuracy: 0.9936 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0162 - accuracy: 0.9938 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0164 - accuracy: 0.9937 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0165 - accuracy: 0.9935 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0163 - accuracy: 0.9937 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0158 - accuracy: 0.9940 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0155 - accuracy: 0.9942 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0154 - accuracy: 0.9944 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0152 - accuracy: 0.9946 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0149 - accuracy: 0.9948 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0154 - accuracy: 0.9946 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0151 - accuracy: 0.9948 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0147 - accuracy: 0.9949 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0146 - accuracy: 0.9951 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0144 - accuracy: 0.9952 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0140 - accuracy: 0.9954 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0140 - accuracy: 0.9952 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0137 - accuracy: 0.9953 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0135 - accuracy: 0.9955 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0133 - accuracy: 0.9956 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0138 - accuracy: 0.9954 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0135 - accuracy: 0.9955 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9956 Batch 43\n",
            "44/44 [==============================] - 7s 165ms/step - loss: 0.0133 - accuracy: 0.9957\n",
            "Epoch 23/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.0019 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0011 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 0.0013 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 0.0010 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0015 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0018 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 0.0016 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 0.0031 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 0.0037 - accuracy: 0.9977 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0035 - accuracy: 0.9979 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0032 - accuracy: 0.9981 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0029 - accuracy: 0.9983 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0036 - accuracy: 0.9984 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0039 - accuracy: 0.9978 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0043 - accuracy: 0.9972 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0069 - accuracy: 0.9961 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0067 - accuracy: 0.9963 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0065 - accuracy: 0.9965 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0063 - accuracy: 0.9967 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0061 - accuracy: 0.9969 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0062 - accuracy: 0.9970 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0059 - accuracy: 0.9972 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0107 - accuracy: 0.9968 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0103 - accuracy: 0.9970 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0099 - accuracy: 0.9971 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0114 - accuracy: 0.9964 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0114 - accuracy: 0.9961 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0120 - accuracy: 0.9959 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0116 - accuracy: 0.9960 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0124 - accuracy: 0.9955 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0141 - accuracy: 0.9953 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0140 - accuracy: 0.9951 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0175 - accuracy: 0.9943 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0170 - accuracy: 0.9945 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0191 - accuracy: 0.9940 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0197 - accuracy: 0.9936 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0237 - accuracy: 0.9930 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0244 - accuracy: 0.9923 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0241 - accuracy: 0.9925 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0273 - accuracy: 0.9919 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0283 - accuracy: 0.9914 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0283 - accuracy: 0.9913 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9913 Batch 43\n",
            "44/44 [==============================] - 8s 190ms/step - loss: 0.0287 - accuracy: 0.9914\n",
            "Epoch 24/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0454 - accuracy: 0.9792 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0567 - accuracy: 0.9792 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.1018 - accuracy: 0.9688 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0919 - accuracy: 0.9688 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0856 - accuracy: 0.9708 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 0.0825 - accuracy: 0.9722 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0743 - accuracy: 0.9747 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0737 - accuracy: 0.9740 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0730 - accuracy: 0.9734 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0702 - accuracy: 0.9740 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0672 - accuracy: 0.9754 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0620 - accuracy: 0.9774 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0596 - accuracy: 0.9784 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0559 - accuracy: 0.9799 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0535 - accuracy: 0.9812 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0521 - accuracy: 0.9818 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0498 - accuracy: 0.9822 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0477 - accuracy: 0.9826 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0475 - accuracy: 0.9825 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0469 - accuracy: 0.9823 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0450 - accuracy: 0.9831 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0430 - accuracy: 0.9839 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0428 - accuracy: 0.9841 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0464 - accuracy: 0.9835 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0463 - accuracy: 0.9837 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0451 - accuracy: 0.9840 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0439 - accuracy: 0.9842 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0431 - accuracy: 0.9844 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0417 - accuracy: 0.9849 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0407 - accuracy: 0.9854 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0410 - accuracy: 0.9856 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0405 - accuracy: 0.9857 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0395 - accuracy: 0.9861 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0387 - accuracy: 0.9865 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0382 - accuracy: 0.9863 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0382 - accuracy: 0.9864 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0395 - accuracy: 0.9862 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0391 - accuracy: 0.9863 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0385 - accuracy: 0.9864 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0377 - accuracy: 0.9867 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0371 - accuracy: 0.9870 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0364 - accuracy: 0.9874 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9876 Batch 43\n",
            "44/44 [==============================] - 7s 165ms/step - loss: 0.0359 - accuracy: 0.9876\n",
            "Epoch 25/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.0146 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 0.0156 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 0.0136 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 0.0121 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0120 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0103 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 0.0089 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 0.0084 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0082 - accuracy: 0.9988 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0089 - accuracy: 0.9979 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0083 - accuracy: 0.9981 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0082 - accuracy: 0.9983 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0083 - accuracy: 0.9984 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0078 - accuracy: 0.9985 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.0073 - accuracy: 0.9986 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 0.0071 - accuracy: 0.9987 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0116 - accuracy: 0.9975 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0109 - accuracy: 0.9977 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.0104 - accuracy: 0.9978 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 0.0099 - accuracy: 0.9979 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 0.0095 - accuracy: 0.9980 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 0.0091 - accuracy: 0.9981 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0089 - accuracy: 0.9982 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.0092 - accuracy: 0.9978 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 0.0115 - accuracy: 0.9975 Batch 25\n",
            "26/44 [================>.............] - ETA: 4s - loss: 0.0112 - accuracy: 0.9976 Batch 26\n",
            "27/44 [=================>............] - ETA: 4s - loss: 0.0108 - accuracy: 0.9977 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0105 - accuracy: 0.9978 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 0.0101 - accuracy: 0.9978 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 0.0116 - accuracy: 0.9976 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0113 - accuracy: 0.9976 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0110 - accuracy: 0.9977 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0107 - accuracy: 0.9978 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 0.0109 - accuracy: 0.9975 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0115 - accuracy: 0.9970 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0112 - accuracy: 0.9971 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0129 - accuracy: 0.9966 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0127 - accuracy: 0.9967 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 0.0126 - accuracy: 0.9968 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0125 - accuracy: 0.9969 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0130 - accuracy: 0.9967 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0128 - accuracy: 0.9968 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9969 Batch 43\n",
            "44/44 [==============================] - 9s 205ms/step - loss: 0.0129 - accuracy: 0.9967\n",
            "Epoch 26/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0642 - accuracy: 0.9688 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0412 - accuracy: 0.9792 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0290 - accuracy: 0.9861 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0247 - accuracy: 0.9896 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0205 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0182 - accuracy: 0.9931 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0168 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0155 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0151 - accuracy: 0.9942 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0138 - accuracy: 0.9948 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0131 - accuracy: 0.9953 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0122 - accuracy: 0.9957 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0115 - accuracy: 0.9960 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0136 - accuracy: 0.9955 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0131 - accuracy: 0.9958 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0139 - accuracy: 0.9948 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0136 - accuracy: 0.9945 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0163 - accuracy: 0.9942 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0169 - accuracy: 0.9940 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0163 - accuracy: 0.9943 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0158 - accuracy: 0.9945 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0156 - accuracy: 0.9943 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0162 - accuracy: 0.9937 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0157 - accuracy: 0.9939 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0158 - accuracy: 0.9937 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0154 - accuracy: 0.9940 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0211 - accuracy: 0.9934 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0206 - accuracy: 0.9937 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0204 - accuracy: 0.9939 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0201 - accuracy: 0.9941 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0208 - accuracy: 0.9940 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0212 - accuracy: 0.9938 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0210 - accuracy: 0.9940 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0215 - accuracy: 0.9939 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0213 - accuracy: 0.9937 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0219 - accuracy: 0.9936 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0219 - accuracy: 0.9932 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0228 - accuracy: 0.9929 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9931 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0225 - accuracy: 0.9930 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0221 - accuracy: 0.9931 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0218 - accuracy: 0.9931 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9930 Batch 43\n",
            "44/44 [==============================] - 7s 158ms/step - loss: 0.0220 - accuracy: 0.9931\n",
            "Epoch 27/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 10s - loss: 0.0031 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 10s - loss: 0.0020 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 11s - loss: 0.0031 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 10s - loss: 0.0028 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 10s - loss: 0.0028 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 9s - loss: 0.0030 - accuracy: 1.0000  Batch 6\n",
            " 7/44 [===>..........................] - ETA: 9s - loss: 0.0033 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 9s - loss: 0.0050 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 0.0046 - accuracy: 0.9988 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 0.0053 - accuracy: 0.9990 Batch 10\n",
            "11/44 [======>.......................] - ETA: 8s - loss: 0.0049 - accuracy: 0.9991 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 0.0048 - accuracy: 0.9991 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 0.0047 - accuracy: 0.9992 Batch 13\n",
            "14/44 [========>.....................] - ETA: 7s - loss: 0.0127 - accuracy: 0.9978 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.0119 - accuracy: 0.9979 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 0.0112 - accuracy: 0.9980 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 0.0113 - accuracy: 0.9975 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0115 - accuracy: 0.9971 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.0116 - accuracy: 0.9967 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 0.0140 - accuracy: 0.9964 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0157 - accuracy: 0.9960 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0154 - accuracy: 0.9962 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0165 - accuracy: 0.9955 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.0192 - accuracy: 0.9944 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0204 - accuracy: 0.9933 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0246 - accuracy: 0.9928 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0250 - accuracy: 0.9927 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0248 - accuracy: 0.9926 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 0.0244 - accuracy: 0.9928 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0242 - accuracy: 0.9931 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0242 - accuracy: 0.9933 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0245 - accuracy: 0.9932 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0253 - accuracy: 0.9924 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0273 - accuracy: 0.9917 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0277 - accuracy: 0.9914 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0276 - accuracy: 0.9913 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0275 - accuracy: 0.9913 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0275 - accuracy: 0.9910 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0286 - accuracy: 0.9909 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0295 - accuracy: 0.9901 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0305 - accuracy: 0.9896 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0300 - accuracy: 0.9898 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9901 Batch 43\n",
            "44/44 [==============================] - 8s 185ms/step - loss: 0.0303 - accuracy: 0.9900\n",
            "Epoch 28/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0100 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0082 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0089 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0113 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0102 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0131 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0115 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0104 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0098 - accuracy: 0.9988 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0137 - accuracy: 0.9979 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0132 - accuracy: 0.9981 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0129 - accuracy: 0.9983 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0122 - accuracy: 0.9984 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0116 - accuracy: 0.9985 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0122 - accuracy: 0.9979 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0142 - accuracy: 0.9974 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0141 - accuracy: 0.9969 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0134 - accuracy: 0.9971 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0133 - accuracy: 0.9967 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0136 - accuracy: 0.9964 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0130 - accuracy: 0.9965 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0139 - accuracy: 0.9957 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0178 - accuracy: 0.9950 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0178 - accuracy: 0.9948 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0182 - accuracy: 0.9946 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0193 - accuracy: 0.9944 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0202 - accuracy: 0.9942 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0197 - accuracy: 0.9944 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0198 - accuracy: 0.9943 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0202 - accuracy: 0.9937 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0214 - accuracy: 0.9933 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0210 - accuracy: 0.9935 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0213 - accuracy: 0.9934 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0212 - accuracy: 0.9933 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0217 - accuracy: 0.9929 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0220 - accuracy: 0.9928 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0217 - accuracy: 0.9930 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0214 - accuracy: 0.9929 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0209 - accuracy: 0.9931 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0207 - accuracy: 0.9932 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0203 - accuracy: 0.9934 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0200 - accuracy: 0.9936 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9937 Batch 43\n",
            "44/44 [==============================] - 7s 171ms/step - loss: 0.0194 - accuracy: 0.9938\n",
            "Epoch 29/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 0.0207 - accuracy: 0.9792 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 0.0106 - accuracy: 0.9896 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 0.0075 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 0.0105 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0140 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.0155 - accuracy: 0.9913 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0134 - accuracy: 0.9926 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 0.0143 - accuracy: 0.9922 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0128 - accuracy: 0.9931 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0136 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0126 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0120 - accuracy: 0.9939 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0112 - accuracy: 0.9944 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0104 - accuracy: 0.9948 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0099 - accuracy: 0.9951 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0121 - accuracy: 0.9948 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0117 - accuracy: 0.9951 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0119 - accuracy: 0.9948 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0114 - accuracy: 0.9951 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0116 - accuracy: 0.9948 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0111 - accuracy: 0.9950 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0106 - accuracy: 0.9953 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0111 - accuracy: 0.9950 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0107 - accuracy: 0.9952 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0106 - accuracy: 0.9954 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0105 - accuracy: 0.9956 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0102 - accuracy: 0.9958 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0098 - accuracy: 0.9959 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0096 - accuracy: 0.9960 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0093 - accuracy: 0.9962 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0116 - accuracy: 0.9956 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0119 - accuracy: 0.9954 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0118 - accuracy: 0.9953 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0115 - accuracy: 0.9954 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0114 - accuracy: 0.9955 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0110 - accuracy: 0.9957 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0108 - accuracy: 0.9958 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0106 - accuracy: 0.9959 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0121 - accuracy: 0.9955 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0133 - accuracy: 0.9951 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0130 - accuracy: 0.9952 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0127 - accuracy: 0.9953 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9954 Batch 43\n",
            "44/44 [==============================] - 7s 165ms/step - loss: 0.0124 - accuracy: 0.9955\n",
            "Epoch 30/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 9.8215e-04 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0143 - accuracy: 0.9896     Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0109 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0143 - accuracy: 0.9896 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0136 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0125 - accuracy: 0.9931 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0117 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0107 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0105 - accuracy: 0.9954 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0103 - accuracy: 0.9948 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0119 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0136 - accuracy: 0.9931 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0166 - accuracy: 0.9920 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0171 - accuracy: 0.9911 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0183 - accuracy: 0.9910 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0177 - accuracy: 0.9915 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0168 - accuracy: 0.9920 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0158 - accuracy: 0.9925 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0192 - accuracy: 0.9918 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0183 - accuracy: 0.9922 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0176 - accuracy: 0.9926 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0172 - accuracy: 0.9929 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0179 - accuracy: 0.9928 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0172 - accuracy: 0.9931 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0169 - accuracy: 0.9933 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0170 - accuracy: 0.9932 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0165 - accuracy: 0.9934 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0164 - accuracy: 0.9937 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0179 - accuracy: 0.9935 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0177 - accuracy: 0.9934 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0172 - accuracy: 0.9936 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0171 - accuracy: 0.9938 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0168 - accuracy: 0.9940 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0173 - accuracy: 0.9939 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0174 - accuracy: 0.9937 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0176 - accuracy: 0.9936 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0172 - accuracy: 0.9938 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0169 - accuracy: 0.9940 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0171 - accuracy: 0.9939 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0170 - accuracy: 0.9940 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0170 - accuracy: 0.9939 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0185 - accuracy: 0.9938 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9937 Batch 43\n",
            "44/44 [==============================] - 8s 193ms/step - loss: 0.0184 - accuracy: 0.9938\n",
            "Epoch 31/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.0032 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0029 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0054 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0064 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0054 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 0.0073 - accuracy: 0.9948 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 0.0081 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0077 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0078 - accuracy: 0.9942 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0105 - accuracy: 0.9937 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0096 - accuracy: 0.9943 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0090 - accuracy: 0.9948 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0091 - accuracy: 0.9944 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0085 - accuracy: 0.9948 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0080 - accuracy: 0.9951 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0097 - accuracy: 0.9948 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0104 - accuracy: 0.9945 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0113 - accuracy: 0.9942 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0108 - accuracy: 0.9945 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0103 - accuracy: 0.9948 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0104 - accuracy: 0.9945 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0102 - accuracy: 0.9948 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0120 - accuracy: 0.9946 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0115 - accuracy: 0.9948 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0114 - accuracy: 0.9950 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0112 - accuracy: 0.9952 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0109 - accuracy: 0.9954 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0108 - accuracy: 0.9955 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0105 - accuracy: 0.9957 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0102 - accuracy: 0.9958 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0100 - accuracy: 0.9960 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0098 - accuracy: 0.9961 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0098 - accuracy: 0.9962 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0096 - accuracy: 0.9963 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0095 - accuracy: 0.9964 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0094 - accuracy: 0.9965 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0091 - accuracy: 0.9966 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0090 - accuracy: 0.9967 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0097 - accuracy: 0.9965 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0096 - accuracy: 0.9966 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0094 - accuracy: 0.9967 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0093 - accuracy: 0.9968 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9966 Batch 43\n",
            "44/44 [==============================] - 8s 179ms/step - loss: 0.0094 - accuracy: 0.9967\n",
            "Epoch 32/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0074 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0038 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0113 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0086 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0069 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 0.0060 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0052 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0055 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0051 - accuracy: 0.9988 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0046 - accuracy: 0.9990 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0050 - accuracy: 0.9981 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0049 - accuracy: 0.9983 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0047 - accuracy: 0.9984 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0044 - accuracy: 0.9985 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0045 - accuracy: 0.9986 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0043 - accuracy: 0.9987 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0050 - accuracy: 0.9982 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0048 - accuracy: 0.9983 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0050 - accuracy: 0.9978 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0047 - accuracy: 0.9979 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0048 - accuracy: 0.9980 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0047 - accuracy: 0.9981 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0045 - accuracy: 0.9982 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 0.0044 - accuracy: 0.9983 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0043 - accuracy: 0.9983 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0043 - accuracy: 0.9984 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0041 - accuracy: 0.9985 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 0.0041 - accuracy: 0.9985 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0040 - accuracy: 0.9986 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0040 - accuracy: 0.9986 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0039 - accuracy: 0.9987 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0038 - accuracy: 0.9987 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0037 - accuracy: 0.9987 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0036 - accuracy: 0.9988 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0035 - accuracy: 0.9988 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0036 - accuracy: 0.9988 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0035 - accuracy: 0.9989 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0034 - accuracy: 0.9989 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990 Batch 43\n",
            "44/44 [==============================] - 8s 181ms/step - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 33/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 7.2161e-05 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 7.7179e-05 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 6.5858e-05 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 4.9778e-05 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 4.2046e-04 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 4.1417e-04 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0012 - accuracy: 1.0000     Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0011 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 9.7729e-04 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 8.8170e-04 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 8.1323e-04 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 7.4761e-04 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 7.0373e-04 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 6.5536e-04 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 6.1339e-04 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.8328e-04 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 6.1578e-04 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 5.8182e-04 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 5.5175e-04 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 5.2625e-04 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 5.0150e-04 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 4.7904e-04 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 4.5866e-04 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 4.4460e-04 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.2705e-04 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 4.1171e-04 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 4.3197e-04 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 4.1782e-04 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 4.0344e-04 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 4.1499e-04 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 4.0237e-04 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 3.8982e-04 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 3.7808e-04 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 3.6702e-04 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 3.5657e-04 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.4678e-04 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 3.3746e-04 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 3.3782e-04 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 3.2934e-04 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.2151e-04 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.1372e-04 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.0638e-04 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.9952e-04 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 168ms/step - loss: 2.9540e-04 - accuracy: 1.0000\n",
            "Epoch 34/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 10s - loss: 4.7888e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 3.3325e-06 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 6.8506e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 6.4367e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 8.4101e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 3.0987e-05 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 2.6885e-05 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 2.4019e-05 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 2.1430e-05 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 1.9794e-05 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 1.8066e-05 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 1.6759e-05 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 1.7127e-05 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 1.6406e-05 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 1.6223e-05 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 1.6094e-05 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 1.5309e-05 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 1.4600e-05 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 1.3949e-05 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 1.3642e-05 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 1.3836e-05 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 1.3419e-05 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 1.2870e-05 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.2712e-05 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.4740e-05 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.4320e-05 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.3841e-05 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 1.3463e-05 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.3343e-05 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.2989e-05 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.3953e-05 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.3582e-05 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.3200e-05 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.2838e-05 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.2496e-05 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.2186e-05 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.2494e-05 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.2212e-05 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.2526e-05 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.2264e-05 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.1988e-05 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.1766e-05 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.1553e-05 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 183ms/step - loss: 1.1399e-05 - accuracy: 1.0000\n",
            "Epoch 35/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 8.0075e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 4.3968e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 5.7658e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 4.9098e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 5.2813e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 5.1001e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 5.2873e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 5.0420e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 5.9186e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 5.3420e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 4.9096e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 4.8098e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 5.5864e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 5.2515e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 5.4711e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.2089e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 5.1224e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 4.8700e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 4.7542e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 5.0954e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 4.9554e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 5.3220e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 5.1609e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 5.0749e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.8767e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 4.7135e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 4.6274e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 4.6879e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 4.5626e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 4.4713e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 4.4219e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 4.3752e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 4.4327e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 4.3738e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 4.2647e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 4.2328e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 5.1401e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 5.2521e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 5.2757e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 5.1718e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 5.0720e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 5.1958e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 5.1398e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 195ms/step - loss: 5.1387e-06 - accuracy: 1.0000\n",
            "Epoch 36/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 13s - loss: 1.3535e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 11s - loss: 6.8109e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 1.4143e-06 - accuracy: 1.0000  Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 7.3562e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 8.1863e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 7.2654e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 6.4757e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 5.7185e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 5.1408e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 5.4589e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 5.0767e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 4.9571e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 4.9065e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 4.9279e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 5.1345e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.1471e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 4.9444e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 5.0860e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 4.9263e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 5.0350e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 4.8584e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 5.1350e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 5.0573e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 4.8960e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.7221e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 4.5868e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 4.4749e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 4.3365e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 4.4591e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 4.3384e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 4.5544e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 4.4608e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 4.5170e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 4.5412e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 4.5258e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 4.4199e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.3994e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 4.3719e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 4.3594e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.2877e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.2057e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.1642e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.1172e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 4.0777e-06 - accuracy: 1.0000\n",
            "Epoch 37/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 1.1697e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 2.6675e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.9857e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.4994e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 2.2563e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 2.4336e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 2.6899e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 2.9214e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 2.9795e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 2.9555e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 2.9549e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 2.7446e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 2.6694e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.6628e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 3.0126e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 2.8362e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.6847e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.6319e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 2.5207e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 2.5376e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 2.4945e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 2.4529e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 2.3888e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.3350e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 2.2842e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 2.2563e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 2.2226e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 2.5987e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 2.8198e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.7705e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.9713e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.8865e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 2.8904e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 2.8747e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.8103e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.7509e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.7776e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.7328e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 2.8614e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.9394e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.0416e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.9802e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.2556e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 202ms/step - loss: 3.2597e-06 - accuracy: 1.0000\n",
            "Epoch 38/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 5.6243e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 3.0027e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 2.4857e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.3166e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 2.2640e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 2.0876e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 3.3429e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 3.1723e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 3.0310e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 3.2284e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 3.4745e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 3.5964e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 3.3946e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 3.2411e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 3.0676e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 2.9979e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.8407e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.9027e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 2.9166e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 2.7861e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 2.6729e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 2.7204e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.6216e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.5807e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 2.6288e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 2.6452e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.5517e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.5292e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.4445e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.3698e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.3256e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.3040e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.2617e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.3287e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.2834e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.2353e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.5831e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.5921e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.5547e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.5933e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.6302e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.7484e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.7191e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 165ms/step - loss: 2.7431e-06 - accuracy: 1.0000\n",
            "Epoch 39/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 6.4775e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 4.2669e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 3.2440e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 3.4435e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 2.9559e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 2.5535e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 2.7203e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 2.5659e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 2.3421e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 2.1574e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 2.0255e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 2.4184e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 2.2562e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 7s - loss: 2.2287e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 2.5031e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 2.4043e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 2.3366e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 6s - loss: 2.2290e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 6s - loss: 2.1529e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 2.1289e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 2.1285e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 2.0579e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 2.0848e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 2.0035e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 1.9862e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 2.1608e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 2.1513e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 2.1683e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 2.1462e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.0920e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.0452e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.2126e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 2.2485e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 2.2244e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.1678e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.1447e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.1161e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.0847e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 2.0352e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.2261e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.2747e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.2428e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.3221e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 199ms/step - loss: 2.3225e-06 - accuracy: 1.0000\n",
            "Epoch 40/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 2.4648e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 2.1252e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 2.3526e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.1131e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 1.8079e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 2.3935e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 2.3719e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 2.2044e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 2.1890e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 2.0217e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.8816e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 2.1017e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 1.9969e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.0556e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.9669e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 2.0435e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.2472e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.1694e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 2.0827e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 2.0135e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.9421e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.8850e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.9126e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.9889e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.9369e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 2.2948e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.2871e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.2871e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.2338e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.1837e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.1809e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.1714e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.1894e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.1396e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.1134e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.1442e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.1788e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.1356e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.1045e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.0607e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.0361e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.0080e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.0155e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 189ms/step - loss: 1.9931e-06 - accuracy: 1.0000\n",
            "Epoch 41/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 10s - loss: 2.4561e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 2.7280e-06 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 2.5392e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 10s - loss: 2.5842e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 10s - loss: 2.3468e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 10s - loss: 2.1682e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 10s - loss: 2.1334e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 9s - loss: 2.2225e-06 - accuracy: 1.0000  Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 2.9445e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 3.0423e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 8s - loss: 2.8228e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 2.6870e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 2.6569e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 2.6168e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 2.5628e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 2.4598e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 2.3267e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 2.4060e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 2.2834e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 2.1870e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 2.1274e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 2.1220e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 2.0577e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.9761e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.9024e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.9833e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.9593e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 1.9086e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.9344e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.8724e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.8368e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.8164e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.7706e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.8006e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.7869e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.8990e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.8497e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.8297e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.8206e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.8027e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.7826e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.7465e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.7207e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 198ms/step - loss: 1.7210e-06 - accuracy: 1.0000\n",
            "Epoch 42/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 3.6508e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 1.5483e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 2.5097e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 2.0999e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 1.7316e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 1.4775e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 1.2878e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 1.4521e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 1.6628e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 1.5755e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 1.6021e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 1.5072e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 1.3953e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 1.3427e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.2585e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 1.2122e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 1.1446e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 1.6341e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 1.5573e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 1.5532e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 1.4851e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 1.5479e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 1.6108e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 1.5814e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 1.5331e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.4787e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.5154e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 1.4908e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 1.4731e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 1.4584e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.5059e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.5388e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.5258e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 1.5431e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.5230e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.4984e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.5265e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.5243e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 1.5336e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.5472e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.5198e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.5150e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.5130e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 209ms/step - loss: 1.4993e-06 - accuracy: 1.0000\n",
            "Epoch 43/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 6.9539e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 1.3181e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 1.0534e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 9.7816e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 1.2020e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 1.5244e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 1.5255e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 1.8194e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 1.8011e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 1.8592e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.7432e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 1.6227e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 1.5150e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 1.4703e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.3835e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.4257e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.5063e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.5693e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.5872e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 1.5117e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.4618e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.4063e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.4813e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.4855e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.4278e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.3929e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.4092e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.3689e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.3644e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.3216e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.4431e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.4247e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.4306e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.4034e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.3903e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.3723e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.3625e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.3360e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.3062e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.3155e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.3191e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.3231e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.3341e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 166ms/step - loss: 1.3221e-06 - accuracy: 1.0000\n",
            "Epoch 44/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 2.9926e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.1374e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 1.0836e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 8.6827e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 7.9743e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 7.1627e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 6.4517e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 5.9122e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 7.0296e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 9.0198e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 8.3082e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 7.8362e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 7.8448e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 8.2769e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 8.0488e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 7.6761e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 7.5190e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 6s - loss: 7.1744e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 6s - loss: 7.4791e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 8.5448e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 9.0354e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 8.9860e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 9.3938e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 9.2942e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 1.1090e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 4s - loss: 1.0815e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.0708e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 1.1584e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 1.2504e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 1.2438e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.2102e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.1958e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.2081e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 1.2146e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.2412e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.2092e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.1952e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.1718e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 1.1830e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.1641e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.1786e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.1537e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.1305e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 200ms/step - loss: 1.1702e-06 - accuracy: 1.0000\n",
            "Epoch 45/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 3.5699e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 1.9017e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 2.6033e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 2.3312e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 1.9434e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 1.8836e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 1.6780e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 1.4855e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 1.4111e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 1.3603e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 1.2530e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 1.1561e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 1.1214e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 1.0684e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.2154e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 1.1679e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.1723e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.1517e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.1667e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 1.1689e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 1.2339e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.1810e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.1550e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.1514e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.1937e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.1632e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.1210e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.1042e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.0979e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.0884e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.0653e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.0748e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.0590e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.0668e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.0460e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.0198e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.0193e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 9.9477e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 9.9384e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 9.7586e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 9.5802e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 9.4997e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.0429e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 184ms/step - loss: 1.0410e-06 - accuracy: 1.0000\n",
            "Epoch 46/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 4.7311e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 11s - loss: 4.9608e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 11s - loss: 1.4359e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 10s - loss: 1.3799e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 10s - loss: 1.2450e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 10s - loss: 1.1666e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 9s - loss: 1.0179e-06 - accuracy: 1.0000  Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 9.2727e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 8.5556e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 7.9310e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 9.1561e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 1.1499e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 1.2057e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 1.2207e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.1442e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 1.2226e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 1.1823e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 1.1276e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.0870e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 1.0511e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 1.0666e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 1.0297e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.0133e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 9.9698e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 9.9465e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 9.8907e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 9.5644e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 9.7053e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 9.4421e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 9.3161e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 9.0296e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 8.9706e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 9.1093e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 8.8717e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 9.3295e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 9.4239e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 9.2736e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 9.4942e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 9.2918e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 9.0791e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 9.1414e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 8.9353e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 9.4329e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 173ms/step - loss: 9.3068e-07 - accuracy: 1.0000\n",
            "Epoch 47/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 1.3212e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 1.0151e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 7.4587e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 6.8699e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 5.5804e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 7.2517e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 1.0723e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 9.6357e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 9.1900e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 8.9230e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 8.5419e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 8.1322e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 8.5679e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 8.3834e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 8.6357e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 8.4072e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 8.6884e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.0137e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 9.6885e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 9.4438e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 9.2377e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 9.1056e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 8.7508e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 8.6097e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 8.4749e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 8.4923e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 8.2173e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 8.5545e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 8.3160e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 8.0483e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 8.3303e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 8.1126e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 8.0869e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 7.8812e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 7.9668e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 7.7876e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 7.6241e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 7.7140e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 8.4685e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 8.4058e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 8.4085e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 8.2598e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 8.1046e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 205ms/step - loss: 8.3569e-07 - accuracy: 1.0000\n",
            "Epoch 48/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 6.7427e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 2.0717e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.5881e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 1.2438e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 1.1053e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 9.8258e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 1.0625e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 9.5750e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 8.9264e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 8.2958e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 7.6556e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 8.5874e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 8.1140e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 8.3380e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 7.8981e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 8.3016e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 8.2399e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 7.9856e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 8.1378e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 7.8948e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 7.6229e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 7.4531e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 7.1782e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 7.0809e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 6.9720e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 6.8209e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 7.1293e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 7.0836e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 7.4375e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 7.4383e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 7.7087e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 7.7914e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 7.6366e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 7.5862e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 7.3758e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 7.2996e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 7.2020e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 7.1785e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 7.2055e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 7.0449e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 6.8937e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 7.0799e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 7.6308e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 166ms/step - loss: 7.5276e-07 - accuracy: 1.0000\n",
            "Epoch 49/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 2.4587e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 4.0170e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 5.1201e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 4.7218e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 4.7211e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 4.6007e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 5.4034e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 4.8801e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 7.2763e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 8.1878e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 7.5710e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 7.3623e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 7.4149e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 7s - loss: 7.5638e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 7.8857e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 7.9012e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 7.6059e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 6s - loss: 7.2627e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 7.2765e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 7.0517e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 7.4302e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 7.3719e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 5s - loss: 7.5021e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 7.5719e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 7.3877e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 4s - loss: 7.2402e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 7.1813e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 7.0494e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 6.9485e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 6.7914e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 6.7161e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 6.5757e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 6.7952e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 6.8196e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 6.7301e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 6.6463e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 6.5080e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 6.3521e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 6.3029e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 6.1810e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 6.1020e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 6.0333e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 6.3267e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 205ms/step - loss: 6.8080e-07 - accuracy: 1.0000\n",
            "Epoch 50/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 3.4024e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 2.7319e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.8916e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.7784e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 5.8683e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 6.4631e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 6.0720e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 8.6220e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 7.7771e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 7.0491e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 6.8756e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 6.5903e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 7.1799e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 7.4458e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 7.2449e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 7.1313e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 7.0449e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 7.0757e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 7.0052e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 6.7537e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 6.4989e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 6.2232e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 6.2923e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 6.0694e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 6.2970e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 6.3242e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 6.4404e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 6.3279e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 6.5546e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 6.5973e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 6.6000e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 6.7973e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 6.7554e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 6.9292e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 6.7404e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 6.5715e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 6.4237e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 6.2828e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 6.2545e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 6.1559e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 6.3343e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 6.2988e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 6.1650e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 184ms/step - loss: 6.1796e-07 - accuracy: 1.0000\n",
            "Epoch 51/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 11s - loss: 3.4397e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 1.4540e-06 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 1.0563e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 1.0846e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 9.7324e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 8.8968e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 9.0822e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 8.0230e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 8.1180e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 7.5235e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 7.1511e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 6.7063e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 6.2735e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 6.9163e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 6.6216e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 6.9303e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 6.8879e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 6.5756e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 6.4073e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 6.2781e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 6.6598e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 6.4163e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 6.6070e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 6.4285e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 6.2682e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 6.4145e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 6.4979e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 6.4264e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 6.2249e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 6.2095e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 6.1670e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 6.2090e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 6.0450e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 5.9314e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 5.8553e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 6.0127e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 5.8640e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 5.7616e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 5.7314e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 5.7182e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 5.7904e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 5.7264e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 5.5988e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 188ms/step - loss: 5.6078e-07 - accuracy: 1.0000\n",
            "Epoch 52/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 5.9728e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 7.0035e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 4.8180e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 4.0481e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 3.7973e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 4.5945e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 5.5488e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 5.0911e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 5.5037e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 5.6599e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 5.4095e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 5.2929e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 5.6088e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 5.2738e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 4.9951e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 4.8257e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 5.1481e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 5.1450e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 4.9559e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 4.8918e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 4.7973e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 4.6633e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 4.6144e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 4.4625e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.3997e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 4.3174e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 4.3645e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 4.3998e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 5.0971e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 4.9839e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 4.9818e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 4.8754e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 4.8202e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 4.9779e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 5.2263e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 5.1642e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 5.1750e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 5.1153e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 5.2315e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 5.4012e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 5.3588e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 5.2440e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 5.1312e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 210ms/step - loss: 5.1148e-07 - accuracy: 1.0000\n",
            "Epoch 53/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 10s - loss: 3.4893e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 2.1855e-07 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 5.6458e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 4.4765e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 3.7799e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 3.2824e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 3.0849e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 2.9740e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 3.5210e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 3.3130e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 3.0457e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 3.7428e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 3.5008e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 3.2942e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 3.4827e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 3.4458e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 4.4170e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 5.8899e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 5.6433e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 5.9851e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 5.9514e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 5.8079e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 5.6072e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 5.4346e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 5.2411e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 5.2707e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 5.0943e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 5.2978e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 5.2058e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 5.2372e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 5.1588e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 5.0201e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 5.0745e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 4.9735e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 4.8431e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 4.9293e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.8065e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 4.8356e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 4.7953e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.6938e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.6299e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.7109e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.6525e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 192ms/step - loss: 4.6937e-07 - accuracy: 1.0000\n",
            "Epoch 54/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 2.3097e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 2.4338e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 2.8850e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 10s - loss: 2.5270e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 10s - loss: 3.8817e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 10s - loss: 3.9343e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 9s - loss: 4.8109e-07 - accuracy: 1.0000  Batch 7\n",
            " 8/44 [====>.........................] - ETA: 9s - loss: 4.8180e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 9s - loss: 4.7973e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 4.4119e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 8s - loss: 4.0436e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 8s - loss: 3.7625e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 8s - loss: 3.5208e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 7s - loss: 3.3385e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 7s - loss: 3.1896e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 7s - loss: 3.2674e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 7s - loss: 3.1738e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 6s - loss: 3.1202e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 6s - loss: 3.3946e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 6s - loss: 4.1772e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 5s - loss: 4.0693e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 4.0847e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 5s - loss: 3.9752e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 3.8463e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 3.7217e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 4s - loss: 3.6884e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 3.6328e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 3.5815e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 3.9817e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 4.2600e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 4.1542e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 4.0682e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 4.1884e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 4.3358e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 4.5770e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 4.6300e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.5401e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 4.5180e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 4.4292e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.3498e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.3152e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.2290e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.3530e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 211ms/step - loss: 4.3055e-07 - accuracy: 1.0000\n",
            "Epoch 55/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 1.4901e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 1.3163e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 1.7799e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 2.1141e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 3.8494e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 3.2658e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 3.1558e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 2.9802e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 2.6560e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 2.5729e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 2.6743e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 2.8954e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 3.1082e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 3.2250e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 3.5738e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 6s - loss: 3.5367e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 3.3841e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 3.7211e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 4.4866e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 4.6894e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 4.5643e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 4.3698e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 4.3623e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 4.2328e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.2214e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 4.1064e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 4.0886e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 3.9616e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 3.9779e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 3.8494e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 3.9427e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 3.9825e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 3.9160e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 3.9192e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 2s - loss: 3.9651e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.9039e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 3.8541e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 3.7726e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 3.7746e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.0751e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.9972e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.0507e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.9848e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 10s 231ms/step - loss: 3.9629e-07 - accuracy: 1.0000\n",
            "Epoch 56/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 2.2103e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 7.6678e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 5.2402e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 4.8552e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 4.8155e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 4.2157e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 5.1994e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 4.8055e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 4.3806e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 4.1896e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 3.8483e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 3.7170e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 3.4712e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 3.6144e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 3.4752e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 3.8750e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 4.0108e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 3.9501e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 3.7481e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 3.8972e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 3.7909e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 3.8697e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 3.7198e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 3.5809e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 3.5742e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 3.4554e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 3.3596e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 3.3815e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 3.3450e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 3.3002e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 3.6303e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 3.6150e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 3.7542e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 4.0437e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 4.0339e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.9967e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 3.9705e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 3.9049e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 3.8892e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.8736e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.8034e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.7876e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.7027e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 9s 203ms/step - loss: 3.6602e-07 - accuracy: 1.0000\n",
            "Epoch 57/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 10s - loss: 6.0846e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 4.4144e-07 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 6.1218e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 5.1346e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 10s - loss: 4.7608e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 10s - loss: 4.9069e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 10s - loss: 4.3088e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 9s - loss: 3.9022e-07 - accuracy: 1.0000  Batch 8\n",
            " 9/44 [=====>........................] - ETA: 9s - loss: 3.5555e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 9s - loss: 3.4198e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 9s - loss: 3.3742e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 9s - loss: 3.2047e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 8s - loss: 3.0843e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 8s - loss: 2.9314e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 8s - loss: 3.1921e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 8s - loss: 3.2138e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 7s - loss: 3.0386e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 7s - loss: 2.8802e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 7s - loss: 2.8371e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 6s - loss: 2.9082e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 6s - loss: 3.0742e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 3.2822e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 5s - loss: 3.3268e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 5s - loss: 3.3781e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 3.3820e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 4s - loss: 3.2701e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 4s - loss: 3.2074e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 3.1443e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 3.1146e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 3.0224e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 3s - loss: 3.0940e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 3.0027e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 3.0784e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 3.0711e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 2s - loss: 3.0902e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.0381e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.9980e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 3.1903e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 3.1458e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.1727e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.4527e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.4361e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.3986e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 3.3829e-07 - accuracy: 1.0000\n",
            "Epoch 58/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 8.4440e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 8.1956e-08 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 1.1631e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 3.8898e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 3.9066e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 3.2865e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 3.3829e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 3.4738e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 3.1403e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 3.2149e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 2.9870e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 2.7743e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 2.8751e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 2.7682e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 2.8237e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 2.9957e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 3.1584e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 3.0188e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 3.0155e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 3.3428e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 3.2144e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 3.5903e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 3.5698e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 3.4986e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 3.5206e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 3.5242e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 3.4682e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 3.4405e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 3.7329e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 3.6900e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 3.5826e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 3.5553e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 3.4769e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 3.5218e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 3.4421e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.3900e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 3.3332e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 3.3057e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 3.2483e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.2661e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.1880e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.1531e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.1240e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 3.1365e-07 - accuracy: 1.0000\n",
            "Epoch 59/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 5.3396e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 1.7509e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 1.9040e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 1.4684e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 1.6565e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 2.9615e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 2.7088e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 2.5906e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 2.3386e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 2.2339e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 2.3819e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 2.2351e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 3.1616e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 2.9802e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 2.7881e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 3.0896e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 3.0430e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.9678e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 2.8671e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 2.8659e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 2.9346e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 2.9446e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.8328e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.7800e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 2.7636e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 2.7495e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 2.7332e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.6400e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.6423e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.6760e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.6505e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.6181e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 2.5456e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.6091e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.7418e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.8336e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.8929e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.8822e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.8799e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.8765e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.9629e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.9370e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.9129e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 186ms/step - loss: 2.9033e-07 - accuracy: 1.0000\n",
            "Epoch 60/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 11s - loss: 8.6923e-09 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 9.8099e-08 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 1.0845e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 1.1021e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 1.9173e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 2.9264e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 2.9216e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 3.2441e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 8s - loss: 2.9650e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 8s - loss: 3.1056e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 8s - loss: 2.8684e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 7s - loss: 2.7246e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 7s - loss: 2.6506e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 7s - loss: 2.6103e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 7s - loss: 2.5712e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 7s - loss: 2.4556e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 6s - loss: 2.7947e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 6s - loss: 2.8326e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 6s - loss: 2.6894e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 6s - loss: 2.6033e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 6s - loss: 2.5604e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 5s - loss: 2.4784e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 5s - loss: 2.6115e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 5s - loss: 2.5358e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 4s - loss: 2.9201e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 4s - loss: 2.9405e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 4s - loss: 3.0745e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 3.0356e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 3s - loss: 3.0080e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 3s - loss: 3.0017e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 3s - loss: 2.9393e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.8580e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 2.8425e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 2s - loss: 2.9338e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 2s - loss: 2.8589e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.7957e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.7795e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.7178e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 1s - loss: 2.7439e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.7992e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.7676e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.7865e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.7272e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 2.6954e-07 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa7155952a0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        print(f' Batch {batch}')\n",
        "        # print(f'Batch {batch}, Loss: {logs[\"loss\"]}, Accuracy: {logs[\"accuracy\"]}')\n",
        "\n",
        "model = build_and_compile_model(normalizer)\n",
        "\n",
        "# Example usage with the custom callback\n",
        "model.fit(train_features, train_labels, epochs=60, batch_size=96, callbacks=[CustomCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is probably overfitting going on as the network gets to be almost 100% accurate on the training data. Ways to counter overfitting is to get more data (this is only about 20 years of NFL data, including playoffs), stuff like dropping neurons mid training to decrease reliance on them, regularization which penalizes large weights of neurons in the network, early stopping, PCA, and several other strategies that I still have to research. This is pretty much a vanilla perceptron type network."
      ],
      "metadata": {
        "id": "2sCFItWW__Ss"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpr6DGyE28h"
      },
      "source": [
        "# **Evaluate accuracy**\n",
        "\n",
        "Next, compare how the model performs on the test dataset (data the model hasn't seen before, generalization):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VflXLEeECaXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48872cf-9766-4fc4-954d-4382a4ff6fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 - 1s - loss: 4.9464 - accuracy: 0.7144 - 785ms/epoch - 24ms/step\n",
            "\n",
            "Test accuracy: 0.7144221663475037\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_features,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "The network is very overfit to the data, must learn and then implement the previously enumerated techniques to reduce this overfitting before using this model to predict next season.\n",
        "\n",
        "*   [Demonstrate overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
        "*   [Strategies to prevent overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PyD1SYE28q"
      },
      "source": [
        "### Make predictions\n",
        "\n",
        "Attach a softmax layer to convert the model's linear outputs—[logits](https://developers.google.com/machine-learning/glossary#logits)—to probabilities, which should be easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnfNA0CrQLSD"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl91RPhdCaXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5bb878-bd23-4e74-c966-3b3a230fc563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 28ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = probability_model.predict(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Here, the model has predicted the label for each input in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DmJEUinCaXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c05c1a3-3a8d-4107-d4ce-c695bb0b85e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.7466217e-29, 0.0000000e+00, 9.9999994e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "predictions[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "A prediction is an array of 3 numbers. They represent the model's \"confidence\" that the image corresponds one of the 3 outcomes (away W, tie, home W). You can see which outcome/label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsqenuPnCaXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afecee6-4f95-4f9f-e2fc-9ffb3a2bddc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "np.argmax(predictions[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So, the model is most confident that this game input is a home win, or `class_names[2]`. Examining the test label shows that this classification is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8911a86e-d5f1-4374-cca7-be6f9ab083bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_labels.iloc[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Define functions to observe the full set of 3 class predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "outputs": [],
      "source": [
        "def visualize_input(i, predictions_array, true_label):\n",
        "    plt.figure(figsize=(20, 5))  # Adjust the figure size as needed\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    # Assuming your input is non-image data\n",
        "    features = test_features.iloc[i]\n",
        "    max_value = features.max()\n",
        "\n",
        "    for idx, (feature_name, feature_value) in enumerate(features.items()):\n",
        "        # Calculate brightness based on the feature value\n",
        "        brightness = feature_value / max_value\n",
        "\n",
        "        # Draw a colored box with brightness based on the feature value\n",
        "        rect = plt.Rectangle((idx / len(features), 0), 1 / len(features), 1, linewidth=0, facecolor=plt.cm.viridis(brightness))\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    true_label_color = 'blue' if predicted_label == true_label else 'red'\n",
        "\n",
        "    # Move the xlabel up slightly for better visibility\n",
        "    plt.xlabel(\"Predicted: {} ({:.2%}), True: {}\".format(class_names[predicted_label],\n",
        "                                                           predictions_array[predicted_label],\n",
        "                                                           class_names[true_label]), color=true_label_color, position=(0, 60), fontsize=16)\n",
        "\n",
        "def feature_info(i, predictions_array, true_label):\n",
        "    # Assuming your input is non-image data\n",
        "    input_str = \", \".join([f\"{feature_name}: {feature_value}\" for feature_name, feature_value in test_features.iloc[i].items()])\n",
        "    print(f\"Input: \\n{input_str}\")\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    class_names = [\"Away Win\", \"Tie\", \"Home Win\"]\n",
        "\n",
        "    if predicted_label == true_label:\n",
        "        out = 'correct prediction'\n",
        "    else:\n",
        "        out = 'incorrect prediction'\n",
        "\n",
        "    print(out)\n",
        "    print(\"Predicted: {} ({:.2%}), True: {}\".format(class_names[predicted_label],\n",
        "                                                     predictions_array[predicted_label],\n",
        "                                                     class_names[true_label]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV5jw-5HwSmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "536ae8cc-9b8a-41cb-effd-d0d25f77ed61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "seasonWeek: 17.0, seasonYear: 2013.0, weekday: 0.0, monthDay: 29.0, month: 3.0, year: 2013.0, militaryTime: 1625.0, stadium: 3.0, field: 6.0, visSeasonWinsComingIntoGame: 6.0, visSeasonTiesComingIntoGame: 10.0, visSeasonLossesComingIntoGame: 0.0, vis_coach_games: 0.0, vis_coach_wins: 0.0, vis_coach_losses: 0.0, vis_coach_ties: 0.0, vis_coach_mean_SRS: 0.0, vis_coach_mean_OSRS: 0.0, vis_coach_mean_DSRS: 0.0, vis_coach_playoff_games: 0.0, vis_coach_playoff_wins: 0.0, vis_coach_playoff_losses: 0.0, vis_coach_mean_division_placement: 0.0, vis_qb_hand: 1.0, vis_qb_height: 183.0, vis_qb_weight: 90.0, vis_qb_age: 28.0, vis_qb_av: 0.0, vis_qb_games: 1.0, vis_qb_wins: 0.0, vis_qb_losses: 1.0, vis_qb_ties: 0.0, vis_qb_cmp_pg: 78.0, vis_qb_patt_pg: 128.0, vis_qb_pyds_pg: 847.0, vis_qb_ptd_pg: 4.0, vis_qb_int_pg: 3.0, vis_qb_p1D_pg: 12.0, vis_qb_psucc_ps: 54.3, vis_qb_plng_ps: 23.0, vis_qb_sk_pg: 13.0, vis_qb_skyds_pg: 67.0, vis_qb_gwd_pg: 0.0, vis_qb_ratt_pg: 18.0, vis_qb_ryds_pg: 38.0, vis_qb_rtd_pg: 2.0, vis_qb_r1d_pg: 0.0, vis_qb_rsucc_ps: 0.0, vis_qb_rlng_ps: 3.0, vis_qb_fmb_pg: 4.0, vis_R1_height: 180.0, vis_R1_weight: 87.0, vis_R1_age: 26.0, vis_R1_av: 23.0, vis_R1_games: 46.0, vis_R1_gs: 21.0, vis_R1_tgts_pg: 3.739130434782609, vis_R1_recs_pg: 2.8260869565217392, vis_R1_cyds_pg: 22.065217391304348, vis_R1_ctd_pg: 0.108695652173913, vis_R1_c1d_pg: 0.9347826086956522, vis_R1_csucc_ps: 43.86666666666667, vis_R1_clng_ps: 42.0, vis_R1_ratt_pg: 11.73913043478261, vis_R1_ryds_pg: 61.391304347826086, vis_R1_rtd_pg: 0.3043478260869565, vis_R1_r1d_pg: 1.9565217391304348, vis_R1_rsucc_ps: 48.96666666666667, vis_R1_rlng_ps: 40.0, vis_R1_fmb_pg: 0.2391304347826087, vis_R2_height: 178.0, vis_R2_weight: 108.0, vis_R2_age: 28.0, vis_R2_av: 0.0, vis_R2_games: 2.0, vis_R2_gs: 1.0, vis_R2_tgts_pg: 4.0, vis_R2_recs_pg: 3.5, vis_R2_cyds_pg: 39.5, vis_R2_ctd_pg: 0.5, vis_R2_c1d_pg: 0.0, vis_R2_csucc_ps: 0.0, vis_R2_clng_ps: 0.0, vis_R2_ratt_pg: 6.0, vis_R2_ryds_pg: 23.0, vis_R2_rtd_pg: 0.5, vis_R2_r1d_pg: 0.0, vis_R2_rsucc_ps: 0.0, vis_R2_rlng_ps: 0.0, vis_R2_fmb_pg: 0.0, vis_R3_height: 183.0, vis_R3_weight: 88.0, vis_R3_age: 21.0, vis_R3_av: 0.0, vis_R3_games: 0.0, vis_R3_gs: 0.0, vis_R3_tgts_pg: 0.0, vis_R3_recs_pg: 0.0, vis_R3_cyds_pg: 0.0, vis_R3_ctd_pg: 0.0, vis_R3_c1d_pg: 0.0, vis_R3_csucc_ps: 0.0, vis_R3_clng_ps: 0.0, vis_R3_ratt_pg: 0.0, vis_R3_ryds_pg: 0.0, vis_R3_rtd_pg: 0.0, vis_R3_r1d_pg: 0.0, vis_R3_rsucc_ps: 0.0, vis_R3_rlng_ps: 0.0, vis_R3_fmb_pg: 0.0, vis_R4_height: 188.0, vis_R4_weight: 95.0, vis_R4_age: 24.0, vis_R4_av: 3.0, vis_R4_games: 15.0, vis_R4_gs: 11.0, vis_R4_tgts_pg: 7.4, vis_R4_recs_pg: 3.4, vis_R4_cyds_pg: 41.4, vis_R4_ctd_pg: 0.1333333333333333, vis_R4_c1d_pg: 1.0, vis_R4_csucc_ps: 37.9, vis_R4_clng_ps: 51.0, vis_R4_ratt_pg: 0.3333333333333333, vis_R4_ryds_pg: 1.2666666666666666, vis_R4_rtd_pg: 0.0, vis_R4_r1d_pg: 0.0, vis_R4_rsucc_ps: 100.0, vis_R4_rlng_ps: 5.0, vis_R4_fmb_pg: 0.0666666666666666, vis_R5_height: 198.0, vis_R5_weight: 120.0, vis_R5_age: 26.0, vis_R5_av: 0.0, vis_R5_games: 26.0, vis_R5_gs: 10.0, vis_R5_tgts_pg: 0.6538461538461539, vis_R5_recs_pg: 0.5, vis_R5_cyds_pg: 3.923076923076923, vis_R5_ctd_pg: 0.0769230769230769, vis_R5_c1d_pg: 0.1153846153846153, vis_R5_csucc_ps: 37.5, vis_R5_clng_ps: 5.5, vis_R5_ratt_pg: 0.0, vis_R5_ryds_pg: 0.0, vis_R5_rtd_pg: 0.0, vis_R5_r1d_pg: 0.0, vis_R5_rsucc_ps: 0.0, vis_R5_rlng_ps: 0.0, vis_R5_fmb_pg: 0.0, vis_D1_height: 198.0, vis_D1_weight: 158.0, vis_D1_age: 29.0, vis_D1_av: 21.0, vis_D1_games: 82.0, vis_D1_gs: 37.0, vis_D1_int_pg: 0.0, vis_D1_pick6_pg: 0.0, vis_D1_pd_pg: 0.0975609756097561, vis_D1_ff_pg: 0.024390243902439, vis_D1_ftd_pg: 0.0, vis_D1_sk_pg: 0.1097560975609756, vis_D1_qbh_pg: 0.3414634146341463, vis_D1_sltk_pg: 1.5, vis_D1_astk_pg: 0.7073170731707317, vis_D1_tfl_pg: 0.2195121951219512, vis_D1_sfty_pg: 0.0, vis_D2_height: 193.0, vis_D2_weight: 136.0, vis_D2_age: 25.0, vis_D2_av: 0.0, vis_D2_games: 1.0, vis_D2_gs: 0.0, vis_D2_int_pg: 0.0, vis_D2_pick6_pg: 0.0, vis_D2_pd_pg: 0.0, vis_D2_ff_pg: 0.0, vis_D2_ftd_pg: 0.0, vis_D2_sk_pg: 1.0, vis_D2_qbh_pg: 2.0, vis_D2_sltk_pg: 7.0, vis_D2_astk_pg: 6.0, vis_D2_tfl_pg: 3.0, vis_D2_sfty_pg: 0.0, vis_D3_height: 185.0, vis_D3_weight: 137.0, vis_D3_age: 30.0, vis_D3_av: 49.0, vis_D3_games: 99.0, vis_D3_gs: 94.0, vis_D3_int_pg: 0.0, vis_D3_pick6_pg: 0.0, vis_D3_pd_pg: 0.0505050505050505, vis_D3_ff_pg: 0.0303030303030303, vis_D3_ftd_pg: 0.0, vis_D3_sk_pg: 0.2929292929292929, vis_D3_qbh_pg: 0.8080808080808081, vis_D3_sltk_pg: 2.686868686868687, vis_D3_astk_pg: 1.4646464646464648, vis_D3_tfl_pg: 0.7373737373737373, vis_D3_sfty_pg: 0.0, vis_D4_height: 198.0, vis_D4_weight: 136.0, vis_D4_age: 28.0, vis_D4_av: 53.0, vis_D4_games: 98.0, vis_D4_gs: 98.0, vis_D4_int_pg: 0.0, vis_D4_pick6_pg: 0.0, vis_D4_pd_pg: 0.1836734693877551, vis_D4_ff_pg: 0.1428571428571428, vis_D4_ftd_pg: 0.010204081632653, vis_D4_sk_pg: 0.7806122448979592, vis_D4_qbh_pg: 1.2653061224489797, vis_D4_sltk_pg: 2.6122448979591835, vis_D4_astk_pg: 0.6632653061224489, vis_D4_tfl_pg: 0.9285714285714286, vis_D4_sfty_pg: 0.0, vis_D5_height: 196.0, vis_D5_weight: 108.0, vis_D5_age: 29.0, vis_D5_av: 40.0, vis_D5_games: 98.0, vis_D5_gs: 82.0, vis_D5_int_pg: 0.0204081632653061, vis_D5_pick6_pg: 0.0, vis_D5_pd_pg: 0.1938775510204081, vis_D5_ff_pg: 0.0816326530612244, vis_D5_ftd_pg: 0.0, vis_D5_sk_pg: 0.2244897959183673, vis_D5_qbh_pg: 0.4489795918367347, vis_D5_sltk_pg: 3.071428571428572, vis_D5_astk_pg: 1.0612244897959184, vis_D5_tfl_pg: 0.4591836734693877, vis_D5_sfty_pg: 0.0, vis_D6_height: 190.0, vis_D6_weight: 108.0, vis_D6_age: 23.0, vis_D6_av: 0.0, vis_D6_games: 0.0, vis_D6_gs: 0.0, vis_D6_int_pg: 0.0, vis_D6_pick6_pg: 0.0, vis_D6_pd_pg: 0.0, vis_D6_ff_pg: 0.0, vis_D6_ftd_pg: 0.0, vis_D6_sk_pg: 0.0, vis_D6_qbh_pg: 0.0, vis_D6_sltk_pg: 0.0, vis_D6_astk_pg: 0.0, vis_D6_tfl_pg: 0.0, vis_D6_sfty_pg: 0.0, vis_D7_height: 188.0, vis_D7_weight: 109.0, vis_D7_age: 24.0, vis_D7_av: 4.0, vis_D7_games: 16.0, vis_D7_gs: 11.0, vis_D7_int_pg: 0.0, vis_D7_pick6_pg: 0.0, vis_D7_pd_pg: 0.125, vis_D7_ff_pg: 0.0, vis_D7_ftd_pg: 0.0, vis_D7_sk_pg: 0.0, vis_D7_qbh_pg: 0.0, vis_D7_sltk_pg: 3.875, vis_D7_astk_pg: 2.25, vis_D7_tfl_pg: 0.1875, vis_D7_sfty_pg: 0.0, vis_D8_height: 180.0, vis_D8_weight: 86.0, vis_D8_age: 28.0, vis_D8_av: 18.0, vis_D8_games: 64.0, vis_D8_gs: 33.0, vis_D8_int_pg: 0.109375, vis_D8_pick6_pg: 0.015625, vis_D8_pd_pg: 0.734375, vis_D8_ff_pg: 0.046875, vis_D8_ftd_pg: 0.0, vis_D8_sk_pg: 0.0, vis_D8_qbh_pg: 0.015625, vis_D8_sltk_pg: 3.046875, vis_D8_astk_pg: 0.5625, vis_D8_tfl_pg: 0.046875, vis_D8_sfty_pg: 0.0, vis_D9_height: 183.0, vis_D9_weight: 86.0, vis_D9_age: 23.0, vis_D9_av: 5.0, vis_D9_games: 16.0, vis_D9_gs: 16.0, vis_D9_int_pg: 0.1875, vis_D9_pick6_pg: 0.0, vis_D9_pd_pg: 1.625, vis_D9_ff_pg: 0.125, vis_D9_ftd_pg: 0.0, vis_D9_sk_pg: 0.0, vis_D9_qbh_pg: 0.0, vis_D9_sltk_pg: 5.0, vis_D9_astk_pg: 0.875, vis_D9_tfl_pg: 0.0625, vis_D9_sfty_pg: 0.0, vis_D10_height: 173.0, vis_D10_weight: 85.0, vis_D10_age: 31.0, vis_D10_av: 30.0, vis_D10_games: 117.0, vis_D10_gs: 67.0, vis_D10_int_pg: 0.1196581196581196, vis_D10_pick6_pg: 0.0085470085470085, vis_D10_pd_pg: 0.2991452991452991, vis_D10_ff_pg: 0.0512820512820512, vis_D10_ftd_pg: 0.0, vis_D10_sk_pg: 0.0427350427350427, vis_D10_qbh_pg: 0.1367521367521367, vis_D10_sltk_pg: 2.8034188034188032, vis_D10_astk_pg: 0.7435897435897436, vis_D10_tfl_pg: 0.1538461538461538, vis_D10_sfty_pg: 0.0, vis_D11_height: 183.0, vis_D11_weight: 92.0, vis_D11_age: 27.0, vis_D11_av: 27.0, vis_D11_games: 62.0, vis_D11_gs: 57.0, vis_D11_int_pg: 0.3548387096774194, vis_D11_pick6_pg: 0.032258064516129, vis_D11_pd_pg: 0.532258064516129, vis_D11_ff_pg: 0.1612903225806451, vis_D11_ftd_pg: 0.0, vis_D11_sk_pg: 0.0483870967741935, vis_D11_qbh_pg: 0.064516129032258, vis_D11_sltk_pg: 4.161290322580645, vis_D11_astk_pg: 1.532258064516129, vis_D11_tfl_pg: 0.2096774193548387, vis_D11_sfty_pg: 0.0, vis_K_age: 28.0, vis_K_av: 15.0, vis_K_games: 77.0, vis_K_fga_pg: 2.389610389610389, vis_K_fgm_pg: 1.9870129870129871, vis_K_fga_0-19_pg: 0.0259740259740259, vis_K_fgm_0-19_pg: 0.0259740259740259, vis_K_fga_20-29_pg: 0.4675324675324675, vis_K_fgm_20-29_pg: 0.4545454545454545, vis_K_fga_30-39_pg: 0.4675324675324675, vis_K_fgm_30-39_pg: 0.4415584415584415, vis_K_fga_40-49_pg: 0.8051948051948052, vis_K_fgm_40-49_pg: 0.6103896103896104, vis_K_fga_50+_pg: 0.2597402597402597, vis_K_fgm_50+_pg: 0.1298701298701298, vis_K_fglng_ps: 54.6, vis_K_xpa_pg: 2.415584415584416, vis_K_xpm_pg: 2.389610389610389, homeSeasonWinsComingIntoGame: 12.0, homeSeasonTiesComingIntoGame: 4.0, homeSeasonLossesComingIntoGame: 0.0, home_coach_games: 288.0, home_coach_wins: 187.0, home_coach_losses: 101.0, home_coach_ties: 0.0, home_coach_mean_SRS: 6.244444444444444, home_coach_mean_OSRS: 3.938888888888888, home_coach_mean_DSRS: 2.322222222222222, home_coach_playoff_games: 26.0, home_coach_playoff_wins: 18.0, home_coach_playoff_losses: 8.0, home_coach_mean_dihomeion_placement: 1.8888888888888888, home_qb_hand: 1.0, home_qb_height: 193.0, home_qb_weight: 102.0, home_qb_age: 36.0, home_qb_av: 179.0, home_qb_games: 201.0, home_qb_wins: 153.0, home_qb_losses: 46.0, home_qb_ties: 0.0, home_qb_cmp_pg: 23.0, home_qb_patt_pg: 36.23880597014925, home_qb_pyds_pg: 268.11442786069654, home_qb_ptd_pg: 1.9651741293532337, home_qb_int_pg: 0.7611940298507462, home_qb_p1D_pg: 12.651741293532336, home_qb_psucc_ps: 46.53076923076923, home_qb_plng_ps: 65.23076923076923, home_qb_sk_pg: 1.845771144278607, home_qb_skyds_pg: 11.611940298507465, home_qb_gwd_pg: 0.1840796019900497, home_qb_ratt_pg: 2.383084577114428, home_qb_ryds_pg: 4.253731343283582, home_qb_rtd_pg: 0.1044776119402985, home_qb_r1d_pg: 0.8208955223880597, home_qb_rsucc_ps: 36.16153846153846, home_qb_rlng_ps: 10.923076923076923, home_qb_fmb_pg: 0.4527363184079602, home_R1_height: 183.0, home_R1_weight: 112.0, home_R1_age: 27.0, home_R1_av: 13.0, home_R1_games: 40.0, home_R1_gs: 21.0, home_R1_tgts_pg: 0.975, home_R1_recs_pg: 0.575, home_R1_cyds_pg: 5.05, home_R1_ctd_pg: 0.0, home_R1_c1d_pg: 0.15, home_R1_csucc_ps: 18.1, home_R1_clng_ps: 14.666666666666666, home_R1_ratt_pg: 13.875, home_R1_ryds_pg: 63.05, home_R1_rtd_pg: 0.45, home_R1_r1d_pg: 1.925, home_R1_rsucc_ps: 42.2, home_R1_rlng_ps: 47.333333333333336, home_R1_fmb_pg: 0.275, home_R2_height: 190.0, home_R2_weight: 115.0, home_R2_age: 25.0, home_R2_av: 0.0, home_R2_games: 1.0, home_R2_gs: 0.0, home_R2_tgts_pg: 4.0, home_R2_recs_pg: 4.0, home_R2_cyds_pg: 62.0, home_R2_ctd_pg: 0.0, home_R2_c1d_pg: 0.0, home_R2_csucc_ps: 0.0, home_R2_clng_ps: 0.0, home_R2_ratt_pg: 3.0, home_R2_ryds_pg: 6.0, home_R2_rtd_pg: 1.0, home_R2_r1d_pg: 0.0, home_R2_rsucc_ps: 0.0, home_R2_rlng_ps: 0.0, home_R2_fmb_pg: 0.0, home_R3_height: 178.0, home_R3_weight: 89.0, home_R3_age: 27.0, home_R3_av: 11.0, home_R3_games: 53.0, home_R3_gs: 15.0, home_R3_tgts_pg: 4.283018867924528, home_R3_recs_pg: 2.830188679245283, home_R3_cyds_pg: 29.37735849056604, home_R3_ctd_pg: 0.1886792452830188, home_R3_c1d_pg: 0.7735849056603774, home_R3_csucc_ps: 90.825, home_R3_clng_ps: 45.75, home_R3_ratt_pg: 0.2641509433962264, home_R3_ryds_pg: 1.5471698113207548, home_R3_rtd_pg: 0.0566037735849056, home_R3_r1d_pg: 0.1132075471698113, home_R3_rsucc_ps: 75.0, home_R3_rlng_ps: 20.5, home_R3_fmb_pg: 0.1320754716981132, home_R4_height: 190.0, home_R4_weight: 95.0, home_R4_age: 22.0, home_R4_av: 0.0, home_R4_games: 0.0, home_R4_gs: 0.0, home_R4_tgts_pg: 0.0, home_R4_recs_pg: 0.0, home_R4_cyds_pg: 0.0, home_R4_ctd_pg: 0.0, home_R4_c1d_pg: 0.0, home_R4_csucc_ps: 0.0, home_R4_clng_ps: 0.0, home_R4_ratt_pg: 0.0, home_R4_ryds_pg: 0.0, home_R4_rtd_pg: 0.0, home_R4_r1d_pg: 0.0, home_R4_rsucc_ps: 0.0, home_R4_rlng_ps: 0.0, home_R4_fmb_pg: 0.0, home_R5_height: 193.0, home_R5_weight: 120.0, home_R5_age: 25.0, home_R5_av: 2.0, home_R5_games: 32.0, home_R5_gs: 18.0, home_R5_tgts_pg: 1.875, home_R5_recs_pg: 1.15625, home_R5_cyds_pg: 14.8125, home_R5_ctd_pg: 0.125, home_R5_c1d_pg: 0.53125, home_R5_csucc_ps: 50.26666666666667, home_R5_clng_ps: 34.666666666666664, home_R5_ratt_pg: 0.0, home_R5_ryds_pg: 0.0, home_R5_rtd_pg: 0.0, home_R5_r1d_pg: 0.0, home_R5_rsucc_ps: 0.0, home_R5_rlng_ps: 0.0, home_R5_fmb_pg: 0.0, home_D1_height: 188.0, home_D1_weight: 117.0, home_D1_age: 29.0, home_D1_av: 25.0, home_D1_games: 78.0, home_D1_gs: 48.0, home_D1_int_pg: 0.0641025641025641, home_D1_pick6_pg: 0.0128205128205128, home_D1_pd_pg: 0.2051282051282051, home_D1_ff_pg: 0.1282051282051282, home_D1_ftd_pg: 0.0, home_D1_sk_pg: 0.391025641025641, home_D1_qbh_pg: 0.717948717948718, home_D1_sltk_pg: 2.4743589743589745, home_D1_astk_pg: 1.9230769230769231, home_D1_tfl_pg: 0.4871794871794871, home_D1_sfty_pg: 0.0, home_D2_height: 185.0, home_D2_weight: 132.0, home_D2_age: 23.0, home_D2_av: 0.0, home_D2_games: 0.0, home_D2_gs: 0.0, home_D2_int_pg: 0.0, home_D2_pick6_pg: 0.0, home_D2_pd_pg: 0.0, home_D2_ff_pg: 0.0, home_D2_ftd_pg: 0.0, home_D2_sk_pg: 0.0, home_D2_qbh_pg: 0.0, home_D2_sltk_pg: 0.0, home_D2_astk_pg: 0.0, home_D2_tfl_pg: 0.0, home_D2_sfty_pg: 0.0, home_D3_height: 188.0, home_D3_weight: 156.0, home_D3_age: 23.0, home_D3_av: 0.0, home_D3_games: 1.0, home_D3_gs: 0.0, home_D3_int_pg: 0.0, home_D3_pick6_pg: 0.0, home_D3_pd_pg: 0.0, home_D3_ff_pg: 0.0, home_D3_ftd_pg: 0.0, home_D3_sk_pg: 2.0, home_D3_qbh_pg: 2.0, home_D3_sltk_pg: 5.0, home_D3_astk_pg: 10.0, home_D3_tfl_pg: 2.0, home_D3_sfty_pg: 0.0, home_D4_height: 196.0, home_D4_weight: 120.0, home_D4_age: 23.0, home_D4_av: 6.0, home_D4_games: 16.0, home_D4_gs: 14.0, home_D4_int_pg: 0.0, home_D4_pick6_pg: 0.0, home_D4_pd_pg: 0.25, home_D4_ff_pg: 0.25, home_D4_ftd_pg: 0.0625, home_D4_sk_pg: 1.09375, home_D4_qbh_pg: 2.1875, home_D4_sltk_pg: 3.9375, home_D4_astk_pg: 3.6875, home_D4_tfl_pg: 1.3125, home_D4_sfty_pg: 0.0, home_D5_height: 190.0, home_D5_weight: 115.0, home_D5_age: 24.0, home_D5_av: 0.0, home_D5_games: 0.0, home_D5_gs: 0.0, home_D5_int_pg: 0.0, home_D5_pick6_pg: 0.0, home_D5_pd_pg: 0.0, home_D5_ff_pg: 0.0, home_D5_ftd_pg: 0.0, home_D5_sk_pg: 0.0, home_D5_qbh_pg: 0.0, home_D5_sltk_pg: 0.0, home_D5_astk_pg: 0.0, home_D5_tfl_pg: 0.0, home_D5_sfty_pg: 0.0, home_D6_height: 190.0, home_D6_weight: 117.0, home_D6_age: 23.0, home_D6_av: 7.0, home_D6_games: 16.0, home_D6_gs: 15.0, home_D6_int_pg: 0.0, home_D6_pick6_pg: 0.0, home_D6_pd_pg: 0.375, home_D6_ff_pg: 0.0, home_D6_ftd_pg: 0.0625, home_D6_sk_pg: 0.3125, home_D6_qbh_pg: 0.9375, home_D6_sltk_pg: 6.25, home_D6_astk_pg: 3.5625, home_D6_tfl_pg: 1.0, home_D6_sfty_pg: 0.0, home_D7_height: 190.0, home_D7_weight: 113.0, home_D7_age: 26.0, home_D7_av: 14.0, home_D7_games: 41.0, home_D7_gs: 33.0, home_D7_int_pg: 0.073170731707317, home_D7_pick6_pg: 0.0, home_D7_pd_pg: 0.3414634146341463, home_D7_ff_pg: 0.1219512195121951, home_D7_ftd_pg: 0.0, home_D7_sk_pg: 0.048780487804878, home_D7_qbh_pg: 0.2195121951219512, home_D7_sltk_pg: 4.853658536585366, home_D7_astk_pg: 3.1707317073170733, home_D7_tfl_pg: 0.3902439024390244, home_D7_sfty_pg: 0.0, home_D8_height: 185.0, home_D8_weight: 94.0, home_D8_age: 27.0, home_D8_av: 23.0, home_D8_games: 66.0, home_D8_gs: 52.0, home_D8_int_pg: 0.3484848484848485, home_D8_pick6_pg: 0.0606060606060606, home_D8_pd_pg: 1.0757575757575757, home_D8_ff_pg: 0.0303030303030303, home_D8_ftd_pg: 0.0, home_D8_sk_pg: 0.0, home_D8_qbh_pg: 0.0, home_D8_sltk_pg: 3.272727272727273, home_D8_astk_pg: 0.4848484848484848, home_D8_tfl_pg: 0.0909090909090909, home_D8_sfty_pg: 0.0, home_D9_height: 180.0, home_D9_weight: 88.0, home_D9_age: 22.0, home_D9_av: 0.0, home_D9_games: 0.0, home_D9_gs: 0.0, home_D9_int_pg: 0.0, home_D9_pick6_pg: 0.0, home_D9_pd_pg: 0.0, home_D9_ff_pg: 0.0, home_D9_ftd_pg: 0.0, home_D9_sk_pg: 0.0, home_D9_qbh_pg: 0.0, home_D9_sltk_pg: 0.0, home_D9_astk_pg: 0.0, home_D9_tfl_pg: 0.0, home_D9_sfty_pg: 0.0, home_D10_height: 180.0, home_D10_weight: 90.0, home_D10_age: 30.0, home_D10_av: 22.0, home_D10_games: 106.0, home_D10_gs: 46.0, home_D10_int_pg: 0.0660377358490566, home_D10_pick6_pg: 0.0094339622641509, home_D10_pd_pg: 0.2735849056603773, home_D10_ff_pg: 0.0188679245283018, home_D10_ftd_pg: 0.0094339622641509, home_D10_sk_pg: 0.0188679245283018, home_D10_qbh_pg: 0.0471698113207547, home_D10_sltk_pg: 2.69811320754717, home_D10_astk_pg: 0.8113207547169812, home_D10_tfl_pg: 0.0471698113207547, home_D10_sfty_pg: 0.0, home_D11_height: 183.0, home_D11_weight: 92.0, home_D11_age: 22.0, home_D11_av: 0.0, home_D11_games: 0.0, home_D11_gs: 0.0, home_D11_int_pg: 0.0, home_D11_pick6_pg: 0.0, home_D11_pd_pg: 0.0, home_D11_ff_pg: 0.0, home_D11_ftd_pg: 0.0, home_D11_sk_pg: 0.0, home_D11_qbh_pg: 0.0, home_D11_sltk_pg: 0.0, home_D11_astk_pg: 0.0, home_D11_tfl_pg: 0.0, home_D11_sfty_pg: 0.0, home_K_age: 29.0, home_K_av: 20.0, home_K_games: 116.0, home_K_fga_pg: 2.2155172413793105, home_K_fgm_pg: 1.896551724137931, home_K_fga_0-19_pg: 0.0086206896551724, home_K_fgm_0-19_pg: 0.0086206896551724, home_K_fga_20-29_pg: 0.603448275862069, home_K_fgm_20-29_pg: 0.5689655172413793, home_K_fga_30-39_pg: 0.7068965517241379, home_K_fgm_30-39_pg: 0.6206896551724138, home_K_fga_40-49_pg: 0.5, home_K_fgm_40-49_pg: 0.3534482758620689, home_K_fga_50+_pg: 0.0948275862068965, home_K_fgm_50+_pg: 0.0689655172413793, home_K_fglng_ps: 49.42857142857143, home_K_xpa_pg: 3.7413793103448274, home_K_xpm_pg: 3.7327586206896552\n",
            "correct prediction\n",
            "Predicted: Home Win (100.00%), True: Home Win\n"
          ]
        }
      ],
      "source": [
        "i = 550  # value within test dataset size 1047 im pretty sure\n",
        "visualize_input(i, predictions[i], test_labels.iloc[i])\n",
        "plt.show()\n",
        "\n",
        "feature_info(i, predictions[i], test_labels.iloc[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "## Use the trained model\n",
        "\n",
        "Finally, use the trained model to make a prediction about a single game."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dict_from_features(feature_names, feature_values):\n",
        "    return dict(zip(feature_names, feature_values))\n",
        "\n",
        "# Example usage\n",
        "feature_names = column_names[1:]\n",
        "feature_values = [22,2023,0,11,5,2024,1830,0,0,14,6,0,386.0,247.0,138.0,1.0,4.720833333333333,2.9250000000000003,1.7874999999999996,38.0,22.0,16.0,1.8333333333333333,1.0,188.0,102.0,27.0,94.0,94.0,75.0,19.0,0.0,27.97872340425532,41.97872340425532,334.4148936170213,2.6595744680851063,0.6595744680851063,14.946808510638299,53.050000000000004,73.33333333333333,1.7659574468085106,11.702127659574469,0.19148936170212766,4.4361702127659575,23.28723404255319,0.24468085106382978,1.3936170212765957,45.28333333333333,22.333333333333332,0.44680851063829785,178.0,97.0,27.0,7.0,20.0,14.0,3.55,3.25,23.5,0.1,0.5,135.7,50.0,22.15,104.35,0.8,2.25,105.7,70.0,0.25,188.0,97.0,27.0,5.0,60.0,9.0,2.1333333333333333,1.1333333333333333,17.1,0.11666666666666667,0.5,53.08,27.4,0.0,0.0,0.016666666666666666,0.0,0.0,0.0,0.016666666666666666,193.0,93.0,27.0,26.0,83.0,54.0,4.819277108433735,2.4698795180722892,42.33734939759036,0.2289156626506024,1.5421686746987953,86.42,86.2,0.10843373493975904,0.5783132530120482,0.0,0.03614457831325301,35.0,7.2,0.012048192771084338,188.0,92.0,27.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,196.0,113.0,27.0,100.0,162.0,155.0,8.950617283950617,6.5246913580246915,80.74074074074075,0.5740740740740741,3.8950617283950617,111.88000000000002,71.6,0.06172839506172839,0.12962962962962962,0.012345679012345678,0.037037037037037035,45.0,1.3,0.08641975308641975,193.0,119.0,27.0,7.0,20.0,20.0,0.0,0.0,0.55,0.0,0.0,0.875,1.5,2.65,1.9,0.9,0.0,188.0,116.0,27.0,5.0,52.0,7.0,0.0,0.0,0.07692307692307693,0.07692307692307693,0.0,0.3269230769230769,0.8269230769230769,1.4423076923076923,1.2884615384615385,0.3076923076923077,0.0,198.0,140.0,27.0,71.0,122.0,99.0,0.01639344262295082,0.00819672131147541,0.39344262295081966,0.10655737704918032,0.0,0.639344262295082,1.5491803278688525,1.680327868852459,0.8032786885245902,0.6721311475409836,0.00819672131147541,193.0,149.0,27.0,18.0,128.0,20.0,0.0,0.0,0.0390625,0.015625,0.0,0.015625,0.1328125,0.9765625,0.765625,0.0859375,0.0,190.0,113.0,27.0,4.0,20.0,8.0,0.0,0.0,0.0,0.0,0.0,0.1,0.15,1.15,0.9,0.2,0.0,188.0,106.0,27.0,14.0,48.0,28.0,0.041666666666666664,0.0,0.16666666666666666,0.041666666666666664,0.0,0.20833333333333334,0.3541666666666667,5.604166666666667,2.5,0.5416666666666666,0.0,180.0,107.0,27.0,13.0,39.0,34.0,0.07692307692307693,0.0,0.2564102564102564,0.02564102564102564,0.05128205128205128,0.05128205128205128,0.2564102564102564,6.538461538461538,4.256410256410256,0.5897435897435898,0.0,185.0,87.0,27.0,14.0,50.0,47.0,0.22,0.0,0.9,0.1,0.0,0.17,0.3,5.44,2.02,0.46,0.0,180.0,87.0,27.0,3.0,14.0,14.0,0.0,0.0,1.5,0.5,0.0,0.2857142857142857,0.6428571428571429,7.357142857142857,2.857142857142857,0.5,0.0,185.0,93.0,27.0,23.0,80.0,76.0,0.1,0.0125,0.5125,0.0375,0.0,0.0875,0.225,4.975,1.75,0.2625,0.0,178.0,92.0,27.0,14.0,65.0,26.0,0.16923076923076924,0.046153846153846156,0.49230769230769234,0.015384615384615385,0.015384615384615385,0.046153846153846156,0.06153846153846154,2.7846153846153845,1.353846153846154,0.15384615384615385,0.0,27.0,22.0,105.0,2.380952380952381,2.1142857142857143,0.01904761904761905,0.01904761904761905,0.45714285714285713,0.45714285714285713,0.6190476190476191,0.580952380952381,0.5333333333333333,0.44761904761904764,0.38095238095238093,0.2571428571428571,56.5,3.723809523809524,3.5238095238095237,14,5,0,98.0,52.0,46.0,0.0,2.516666666666667,1.45,1.05,9.0,6.0,3.0,2.6666666666666665,1.0,185.0,99.0,27.0,6.0,12.0,7.0,1.0,0.0,36.083333333333336,52.416666666666664,490.0833333333333,3.6666666666666665,1.25,7.75,50.3,54.0,3.0833333333333335,19.25,0.16666666666666666,5.5,17.666666666666668,0.5833333333333334,0.6666666666666666,27.3,13.0,0.16666666666666666,180.0,92.0,27.0,63.0,79.0,72.0,8.405063291139241,6.772151898734177,57.43037974683544,0.3924050632911392,2.6455696202531644,74.95,46.333333333333336,17.189873417721518,81.9620253164557,0.7341772151898734,3.0253164556962027,62.76666666666666,56.666666666666664,0.13924050632911392,188.0,106.0,27.0,22.0,166.0,121.0,2.2048192771084336,1.6626506024096386,15.674698795180722,0.10240963855421686,0.6927710843373494,75.57000000000001,40.5,0.4036144578313253,1.4216867469879517,0.030120481927710843,0.18674698795180722,52.5,8.8,0.04819277108433735,183.0,90.0,27.0,24.0,52.0,50.0,8.423076923076923,5.576923076923077,82.21153846153847,0.5,2.673076923076923,96.96666666666668,71.33333333333333,0.25,2.25,0.038461538461538464,0.07692307692307693,68.89999999999999,20.666666666666668,0.07692307692307693,183.0,97.0,27.0,35.0,60.0,52.0,8.233333333333333,5.433333333333334,78.78333333333333,0.35,2.4833333333333334,88.725,91.25,3.4833333333333334,21.45,0.3333333333333333,0.75,97.975,55.25,0.18333333333333332,193.0,113.0,27.0,46.0,91.0,83.0,7.549450549450549,5.395604395604396,73.9010989010989,0.42857142857142855,2.912087912087912,86.43333333333334,68.33333333333333,0.14285714285714285,0.8241758241758241,0.0,0.03296703296703297,73.33333333333333,8.333333333333334,0.04395604395604396,196.0,119.0,27.0,19.0,28.0,27.0,0.0,0.0,0.32142857142857145,0.21428571428571427,0.03571428571428571,0.5892857142857143,1.1428571428571428,2.607142857142857,1.2857142857142858,0.75,0.0,188.0,138.0,27.0,52.0,119.0,104.0,0.0,0.0,0.07563025210084033,0.03361344537815126,0.008403361344537815,0.39915966386554624,0.6890756302521008,1.8739495798319328,1.4789915966386555,0.4957983193277311,0.0,193.0,120.0,27.0,43.0,60.0,58.0,0.016666666666666666,0.0,0.16666666666666666,0.2,0.0,1.0583333333333333,2.683333333333333,3.033333333333333,1.1833333333333333,1.3833333333333333,0.0,201.0,131.0,27.0,42.0,113.0,94.0,0.0,0.0,0.05309734513274336,0.035398230088495575,0.0,0.3584070796460177,0.8849557522123894,1.7433628318584071,1.2123893805309736,0.4247787610619469,0.0,183.0,104.0,27.0,23.0,56.0,48.0,0.08928571428571429,0.017857142857142856,0.30357142857142855,0.05357142857142857,0.017857142857142856,0.0625,0.17857142857142858,6.0,3.1964285714285716,0.39285714285714285,0.0,190.0,104.0,27.0,60.0,90.0,90.0,0.1111111111111111,0.011111111111111112,0.5666666666666667,0.13333333333333333,0.0,0.1,0.3111111111111111,6.088888888888889,3.3555555555555556,0.43333333333333335,0.0,183.0,86.0,27.0,3.0,29.0,7.0,0.06896551724137931,0.0,0.4482758620689655,0.034482758620689655,0.0,0.0,0.0,2.8275862068965516,0.8275862068965517,0.034482758620689655,0.0,185.0,88.0,27.0,20.0,87.0,73.0,0.11494252873563218,0.011494252873563218,0.8735632183908046,0.034482758620689655,0.0,0.011494252873563218,0.034482758620689655,3.9080459770114944,1.3103448275862069,0.09195402298850575,0.0,185.0,96.0,27.0,65.0,164.0,156.0,0.20121951219512196,0.018292682926829267,0.4268292682926829,0.018292682926829267,0.0,0.021341463414634148,0.042682926829268296,3.152439024390244,1.2073170731707317,0.11585365853658537,0.0,180.0,91.0,27.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,178.0,90.0,27.0,6.0,33.0,18.0,0.18181818181818182,0.0,0.5757575757575758,0.0,0.0,0.030303030303030304,0.06060606060606061,4.363636363636363,1.9090909090909092,0.24242424242424243,0.0,27.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n"
      ],
      "metadata": {
        "id": "cNelw1nMBSwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0920ba5-26b0-4d1b-9f7e-ad78e954a194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(701,)\n",
            "seasonWeek             22.0\n",
            "seasonYear           2023.0\n",
            "weekday                 0.0\n",
            "monthDay               11.0\n",
            "month                   5.0\n",
            "                      ...  \n",
            "home_K_fga_50+_pg       0.0\n",
            "home_K_fgm_50+_pg       0.0\n",
            "home_K_fglng_ps         0.0\n",
            "home_K_xpa_pg           0.0\n",
            "home_K_xpm_pg           0.0\n",
            "Length: 701, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Grab an image from the test dataset.\n",
        "# singleGame = test_features.iloc[500]\n",
        "\n",
        "# print(singleGame.shape)\n",
        "# print(singleGame)\n",
        "\n",
        "\n",
        "singleGame_data = create_dict_from_features(feature_names, feature_values)\n",
        "singleGame = pd.Series(singleGame_data)\n",
        "\n",
        "print(singleGame.shape)\n",
        "print(singleGame)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDFh5yF_CaXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536c1ea6-d3a5-4965-a241-9d1bef08940b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 701)\n"
          ]
        }
      ],
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "singleGame = (np.expand_dims(singleGame,0))\n",
        "\n",
        "print(singleGame.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Now predict the correct label for this game:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b64e1f-07ed-46c3-e56a-f0ec9526328d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step\n",
            "[[1.9972697e-03 7.6730799e-10 9.9800271e-01]]\n"
          ]
        }
      ],
      "source": [
        "predictions_single = probability_model.predict(singleGame)\n",
        "\n",
        "print(predictions_single)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`tf.keras.Model.predict` returns a list of lists—one list for each game input in the batch of data. Grab the predictions for our (only) game in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tRmdq_8CaXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baecd978-7db8-4e2d-b6ff-c51b92379de8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "np.argmax(predictions_single[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 500\n",
        "visualize_input(i, predictions[i], test_labels.iloc[i])\n",
        "plt.show()\n",
        "\n",
        "feature_info(i, predictions[i], test_labels.iloc[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "Cn8pAqP2qF34",
        "outputId": "35bfd5e9-b8a0-41a4-ca45-75873f02a9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "seasonWeek: 2.0, seasonYear: 2013.0, weekday: 4.0, monthDay: 12.0, month: 0.0, year: 2013.0, militaryTime: 2029.0, stadium: 3.0, field: 6.0, visSeasonWinsComingIntoGame: 1.0, visSeasonTiesComingIntoGame: 1.0, visSeasonLossesComingIntoGame: 0.0, vis_coach_games: 64.0, vis_coach_wins: 34.0, vis_coach_losses: 30.0, vis_coach_ties: 0.0, vis_coach_mean_SRS: 2.525, vis_coach_mean_OSRS: -0.1499999999999999, vis_coach_mean_DSRS: 2.625, vis_coach_playoff_games: 6.0, vis_coach_playoff_wins: 4.0, vis_coach_playoff_losses: 2.0, vis_coach_mean_division_placement: 2.25, vis_qb_hand: 1.0, vis_qb_height: 190.0, vis_qb_weight: 100.0, vis_qb_age: 23.0, vis_qb_av: 0.0, vis_qb_games: 0.0, vis_qb_wins: 0.0, vis_qb_losses: 0.0, vis_qb_ties: 0.0, vis_qb_cmp_pg: 0.0, vis_qb_patt_pg: 0.0, vis_qb_pyds_pg: 0.0, vis_qb_ptd_pg: 0.0, vis_qb_int_pg: 0.0, vis_qb_p1D_pg: 0.0, vis_qb_psucc_ps: 0.0, vis_qb_plng_ps: 0.0, vis_qb_sk_pg: 0.0, vis_qb_skyds_pg: 0.0, vis_qb_gwd_pg: 0.0, vis_qb_ratt_pg: 0.0, vis_qb_ryds_pg: 0.0, vis_qb_rtd_pg: 0.0, vis_qb_r1d_pg: 0.0, vis_qb_rsucc_ps: 0.0, vis_qb_rlng_ps: 0.0, vis_qb_fmb_pg: 0.0, vis_R1_height: 178.0, vis_R1_weight: 92.0, vis_R1_age: 25.0, vis_R1_av: 3.0, vis_R1_games: 16.0, vis_R1_gs: 2.0, vis_R1_tgts_pg: 2.625, vis_R1_recs_pg: 1.375, vis_R1_cyds_pg: 11.375, vis_R1_ctd_pg: 0.0, vis_R1_c1d_pg: 0.5625, vis_R1_csucc_ps: 16.65, vis_R1_clng_ps: 11.5, vis_R1_ratt_pg: 8.4375, vis_R1_ryds_pg: 30.4375, vis_R1_rtd_pg: 0.25, vis_R1_r1d_pg: 1.5625, vis_R1_rsucc_ps: 23.2, vis_R1_rlng_ps: 12.0, vis_R1_fmb_pg: 0.125, vis_R2_height: 180.0, vis_R2_weight: 85.0, vis_R2_age: 27.0, vis_R2_av: 2.0, vis_R2_games: 26.0, vis_R2_gs: 2.0, vis_R2_tgts_pg: 1.4230769230769231, vis_R2_recs_pg: 0.7307692307692307, vis_R2_cyds_pg: 10.0, vis_R2_ctd_pg: 0.0, vis_R2_c1d_pg: 0.5, vis_R2_csucc_ps: 22.75, vis_R2_clng_ps: 26.5, vis_R2_ratt_pg: 0.0769230769230769, vis_R2_ryds_pg: 0.6153846153846154, vis_R2_rtd_pg: 0.0, vis_R2_r1d_pg: 0.0769230769230769, vis_R2_rsucc_ps: 50.0, vis_R2_rlng_ps: 8.0, vis_R2_fmb_pg: 0.0, vis_R3_height: 180.0, vis_R3_weight: 87.0, vis_R3_age: 29.0, vis_R3_av: 50.0, vis_R3_games: 99.0, vis_R3_gs: 83.0, vis_R3_tgts_pg: 7.212121212121212, vis_R3_recs_pg: 3.878787878787879, vis_R3_cyds_pg: 59.81818181818182, vis_R3_ctd_pg: 0.404040404040404, vis_R3_c1d_pg: 2.898989898989899, vis_R3_csucc_ps: 66.58571428571429, vis_R3_clng_ps: 75.71428571428571, vis_R3_ratt_pg: 0.1818181818181818, vis_R3_ryds_pg: 0.9696969696969696, vis_R3_rtd_pg: 0.0, vis_R3_r1d_pg: 0.0505050505050505, vis_R3_rsucc_ps: 55.71428571428572, vis_R3_rlng_ps: 11.714285714285714, vis_R3_fmb_pg: 0.1717171717171717, vis_R4_height: 193.0, vis_R4_weight: 97.0, vis_R4_age: 22.0, vis_R4_av: 2.0, vis_R4_games: 11.0, vis_R4_gs: 8.0, vis_R4_tgts_pg: 4.2727272727272725, vis_R4_recs_pg: 1.9090909090909087, vis_R4_cyds_pg: 22.90909090909091, vis_R4_ctd_pg: 0.2727272727272727, vis_R4_c1d_pg: 1.5454545454545454, vis_R4_csucc_ps: 42.6, vis_R4_clng_ps: 33.0, vis_R4_ratt_pg: 0.0, vis_R4_ryds_pg: 0.0, vis_R4_rtd_pg: 0.0909090909090909, vis_R4_r1d_pg: 0.0, vis_R4_rsucc_ps: 0.0, vis_R4_rlng_ps: 0.0, vis_R4_fmb_pg: 0.0, vis_R5_height: 193.0, vis_R5_weight: 108.0, vis_R5_age: 30.0, vis_R5_av: 39.0, vis_R5_games: 93.0, vis_R5_gs: 80.0, vis_R5_tgts_pg: 7.741935483870968, vis_R5_recs_pg: 4.78494623655914, vis_R5_cyds_pg: 52.97849462365591, vis_R5_ctd_pg: 0.2580645161290322, vis_R5_c1d_pg: 2.6666666666666665, vis_R5_csucc_ps: 48.0625, vis_R5_clng_ps: 34.0, vis_R5_ratt_pg: 0.010752688172043, vis_R5_ryds_pg: 0.075268817204301, vis_R5_rtd_pg: 0.0, vis_R5_r1d_pg: 0.0, vis_R5_rsucc_ps: 0.0, vis_R5_rlng_ps: 0.875, vis_R5_fmb_pg: 0.075268817204301, vis_D1_height: 190.0, vis_D1_weight: 131.0, vis_D1_age: 23.0, vis_D1_av: 0.0, vis_D1_games: 0.0, vis_D1_gs: 0.0, vis_D1_int_pg: 0.0, vis_D1_pick6_pg: 0.0, vis_D1_pd_pg: 0.0, vis_D1_ff_pg: 0.0, vis_D1_ftd_pg: 0.0, vis_D1_sk_pg: 0.0, vis_D1_qbh_pg: 0.0, vis_D1_sltk_pg: 0.0, vis_D1_astk_pg: 0.0, vis_D1_tfl_pg: 0.0, vis_D1_sfty_pg: 0.0, vis_D2_height: 190.0, vis_D2_weight: 158.0, vis_D2_age: 25.0, vis_D2_av: 0.0, vis_D2_games: 5.0, vis_D2_gs: 0.0, vis_D2_int_pg: 0.0, vis_D2_pick6_pg: 0.0, vis_D2_pd_pg: 0.0, vis_D2_ff_pg: 0.0, vis_D2_ftd_pg: 0.0, vis_D2_sk_pg: 0.0, vis_D2_qbh_pg: 0.0, vis_D2_sltk_pg: 0.8, vis_D2_astk_pg: 0.4, vis_D2_tfl_pg: 0.2, vis_D2_sfty_pg: 0.0, vis_D3_height: 193.0, vis_D3_weight: 142.0, vis_D3_age: 24.0, vis_D3_av: 17.0, vis_D3_games: 32.0, vis_D3_gs: 31.0, vis_D3_int_pg: 0.0, vis_D3_pick6_pg: 0.0, vis_D3_pd_pg: 0.21875, vis_D3_ff_pg: 0.125, vis_D3_ftd_pg: 0.03125, vis_D3_sk_pg: 0.28125, vis_D3_qbh_pg: 0.59375, vis_D3_sltk_pg: 2.25, vis_D3_astk_pg: 1.5, vis_D3_tfl_pg: 0.65625, vis_D3_sfty_pg: 0.03125, vis_D4_height: 190.0, vis_D4_weight: 122.0, vis_D4_age: 29.0, vis_D4_av: 5.0, vis_D4_games: 29.0, vis_D4_gs: 7.0, vis_D4_int_pg: 0.0, vis_D4_pick6_pg: 0.0, vis_D4_pd_pg: 0.0344827586206896, vis_D4_ff_pg: 0.0689655172413793, vis_D4_ftd_pg: 0.0, vis_D4_sk_pg: 0.1206896551724138, vis_D4_qbh_pg: 0.2068965517241379, vis_D4_sltk_pg: 1.2413793103448276, vis_D4_astk_pg: 0.6551724137931034, vis_D4_tfl_pg: 0.1724137931034483, vis_D4_sfty_pg: 0.0, vis_D5_height: 193.0, vis_D5_weight: 120.0, vis_D5_age: 33.0, vis_D5_av: 58.0, vis_D5_games: 145.0, vis_D5_gs: 113.0, vis_D5_int_pg: 0.0206896551724137, vis_D5_pick6_pg: 0.0, vis_D5_pd_pg: 0.1655172413793103, vis_D5_ff_pg: 0.1310344827586207, vis_D5_ftd_pg: 0.0068965517241379, vis_D5_sk_pg: 0.3137931034482759, vis_D5_qbh_pg: 0.4068965517241379, vis_D5_sltk_pg: 2.8482758620689657, vis_D5_astk_pg: 0.8137931034482758, vis_D5_tfl_pg: 0.4689655172413793, vis_D5_sfty_pg: 0.0, vis_D6_height: 188.0, vis_D6_weight: 112.0, vis_D6_age: 24.0, vis_D6_av: 3.0, vis_D6_games: 16.0, vis_D6_gs: 3.0, vis_D6_int_pg: 0.0, vis_D6_pick6_pg: 0.0, vis_D6_pd_pg: 0.0, vis_D6_ff_pg: 0.0, vis_D6_ftd_pg: 0.0, vis_D6_sk_pg: 0.0, vis_D6_qbh_pg: 0.0625, vis_D6_sltk_pg: 2.125, vis_D6_astk_pg: 0.5625, vis_D6_tfl_pg: 0.0625, vis_D6_sfty_pg: 0.0, vis_D7_height: 188.0, vis_D7_weight: 113.0, vis_D7_age: 29.0, vis_D7_av: 58.0, vis_D7_games: 97.0, vis_D7_gs: 90.0, vis_D7_int_pg: 0.0721649484536082, vis_D7_pick6_pg: 0.0103092783505154, vis_D7_pd_pg: 0.2371134020618556, vis_D7_ff_pg: 0.0618556701030927, vis_D7_ftd_pg: 0.0, vis_D7_sk_pg: 0.2525773195876288, vis_D7_qbh_pg: 0.5051546391752577, vis_D7_sltk_pg: 4.948453608247423, vis_D7_astk_pg: 2.1649484536082477, vis_D7_tfl_pg: 0.3402061855670103, vis_D7_sfty_pg: 0.0, vis_D8_height: 183.0, vis_D8_weight: 91.0, vis_D8_age: 22.0, vis_D8_av: 0.0, vis_D8_games: 0.0, vis_D8_gs: 0.0, vis_D8_int_pg: 0.0, vis_D8_pick6_pg: 0.0, vis_D8_pd_pg: 0.0, vis_D8_ff_pg: 0.0, vis_D8_ftd_pg: 0.0, vis_D8_sk_pg: 0.0, vis_D8_qbh_pg: 0.0, vis_D8_sltk_pg: 0.0, vis_D8_astk_pg: 0.0, vis_D8_tfl_pg: 0.0, vis_D8_sfty_pg: 0.0, vis_D9_height: 188.0, vis_D9_weight: 95.0, vis_D9_age: 29.0, vis_D9_av: 54.0, vis_D9_games: 121.0, vis_D9_gs: 95.0, vis_D9_int_pg: 0.2231404958677686, vis_D9_pick6_pg: 0.024793388429752, vis_D9_pd_pg: 0.7272727272727273, vis_D9_ff_pg: 0.0165289256198347, vis_D9_ftd_pg: 0.0082644628099173, vis_D9_sk_pg: 0.0, vis_D9_qbh_pg: 0.0, vis_D9_sltk_pg: 2.4049586776859506, vis_D9_astk_pg: 0.2809917355371901, vis_D9_tfl_pg: 0.0082644628099173, vis_D9_sfty_pg: 0.0, vis_D10_height: 185.0, vis_D10_weight: 96.0, vis_D10_age: 31.0, vis_D10_av: 40.0, vis_D10_games: 103.0, vis_D10_gs: 101.0, vis_D10_int_pg: 0.145631067961165, vis_D10_pick6_pg: 0.029126213592233, vis_D10_pd_pg: 0.3980582524271844, vis_D10_ff_pg: 0.029126213592233, vis_D10_ftd_pg: 0.0, vis_D10_sk_pg: 0.058252427184466, vis_D10_qbh_pg: 0.116504854368932, vis_D10_sltk_pg: 4.466019417475728, vis_D10_astk_pg: 1.3689320388349515, vis_D10_tfl_pg: 0.1844660194174757, vis_D10_sfty_pg: 0.0, vis_D11_height: 185.0, vis_D11_weight: 95.0, vis_D11_age: 25.0, vis_D11_av: 1.0, vis_D11_games: 7.0, vis_D11_gs: 1.0, vis_D11_int_pg: 0.0, vis_D11_pick6_pg: 0.0, vis_D11_pd_pg: 0.0, vis_D11_ff_pg: 0.0, vis_D11_ftd_pg: 0.0, vis_D11_sk_pg: 0.1428571428571428, vis_D11_qbh_pg: 0.1428571428571428, vis_D11_sltk_pg: 1.1428571428571428, vis_D11_astk_pg: 0.5714285714285714, vis_D11_tfl_pg: 0.1428571428571428, vis_D11_sfty_pg: 0.0, vis_K_age: 29.0, vis_K_av: 15.0, vis_K_games: 98.0, vis_K_fga_pg: 1.8265306122448977, vis_K_fgm_pg: 1.4285714285714286, vis_K_fga_0-19_pg: 0.0204081632653061, vis_K_fgm_0-19_pg: 0.0204081632653061, vis_K_fga_20-29_pg: 0.4591836734693877, vis_K_fgm_20-29_pg: 0.3979591836734694, vis_K_fga_30-39_pg: 0.5510204081632653, vis_K_fgm_30-39_pg: 0.4795918367346938, vis_K_fga_40-49_pg: 0.5204081632653061, vis_K_fgm_40-49_pg: 0.3673469387755102, vis_K_fga_50+_pg: 0.2448979591836734, vis_K_fgm_50+_pg: 0.1326530612244898, vis_K_fglng_ps: 52.833333333333336, vis_K_xpa_pg: 2.5816326530612246, vis_K_xpm_pg: 2.5816326530612246, homeSeasonWinsComingIntoGame: 2.0, homeSeasonTiesComingIntoGame: 0.0, homeSeasonLossesComingIntoGame: 0.0, home_coach_games: 288.0, home_coach_wins: 187.0, home_coach_losses: 101.0, home_coach_ties: 0.0, home_coach_mean_SRS: 6.244444444444444, home_coach_mean_OSRS: 3.938888888888888, home_coach_mean_DSRS: 2.322222222222222, home_coach_playoff_games: 26.0, home_coach_playoff_wins: 18.0, home_coach_playoff_losses: 8.0, home_coach_mean_dihomeion_placement: 1.8888888888888888, home_qb_hand: 1.0, home_qb_height: 193.0, home_qb_weight: 102.0, home_qb_age: 36.0, home_qb_av: 179.0, home_qb_games: 201.0, home_qb_wins: 153.0, home_qb_losses: 46.0, home_qb_ties: 0.0, home_qb_cmp_pg: 21.791044776119403, home_qb_patt_pg: 34.3134328358209, home_qb_pyds_pg: 253.9452736318408, home_qb_ptd_pg: 1.8805970149253728, home_qb_int_pg: 0.7263681592039801, home_qb_p1D_pg: 12.651741293532336, home_qb_psucc_ps: 46.53076923076923, home_qb_plng_ps: 65.23076923076923, home_qb_sk_pg: 1.7213930348258706, home_qb_skyds_pg: 10.81592039800995, home_qb_gwd_pg: 0.1840796019900497, home_qb_ratt_pg: 2.298507462686567, home_qb_ryds_pg: 4.119402985074627, home_qb_rtd_pg: 0.0845771144278607, home_qb_r1d_pg: 0.8208955223880597, home_qb_rsucc_ps: 36.16153846153846, home_qb_rlng_ps: 10.923076923076923, home_qb_fmb_pg: 0.4477611940298507, home_R1_height: 190.0, home_R1_weight: 115.0, home_R1_age: 25.0, home_R1_av: 0.0, home_R1_games: 1.0, home_R1_gs: 0.0, home_R1_tgts_pg: 0.0, home_R1_recs_pg: 0.0, home_R1_cyds_pg: 0.0, home_R1_ctd_pg: 0.0, home_R1_c1d_pg: 0.0, home_R1_csucc_ps: 0.0, home_R1_clng_ps: 0.0, home_R1_ratt_pg: 0.0, home_R1_ryds_pg: 0.0, home_R1_rtd_pg: 0.0, home_R1_r1d_pg: 0.0, home_R1_rsucc_ps: 0.0, home_R1_rlng_ps: 0.0, home_R1_fmb_pg: 0.0, home_R2_height: 180.0, home_R2_weight: 99.0, home_R2_age: 24.0, home_R2_av: 15.0, home_R2_games: 35.0, home_R2_gs: 15.0, home_R2_tgts_pg: 0.6285714285714286, home_R2_recs_pg: 0.3142857142857143, home_R2_cyds_pg: 2.3142857142857145, home_R2_ctd_pg: 0.0, home_R2_c1d_pg: 0.0857142857142857, home_R2_csucc_ps: 99.3, home_R2_clng_ps: 22.5, home_R2_ratt_pg: 12.085714285714284, home_R2_ryds_pg: 54.94285714285714, home_R2_rtd_pg: 0.4, home_R2_r1d_pg: 3.2, home_R2_rsucc_ps: 106.4, home_R2_rlng_ps: 54.0, home_R2_fmb_pg: 0.2285714285714285, home_R3_height: 183.0, home_R3_weight: 88.0, home_R3_age: 25.0, home_R3_av: 0.0, home_R3_games: 0.0, home_R3_gs: 0.0, home_R3_tgts_pg: 0.0, home_R3_recs_pg: 0.0, home_R3_cyds_pg: 0.0, home_R3_ctd_pg: 0.0, home_R3_c1d_pg: 0.0, home_R3_csucc_ps: 0.0, home_R3_clng_ps: 0.0, home_R3_ratt_pg: 0.0, home_R3_ryds_pg: 0.0, home_R3_rtd_pg: 0.0, home_R3_r1d_pg: 0.0, home_R3_rsucc_ps: 0.0, home_R3_rlng_ps: 0.0, home_R3_fmb_pg: 0.0, home_R4_height: 178.0, home_R4_weight: 89.0, home_R4_age: 27.0, home_R4_av: 11.0, home_R4_games: 53.0, home_R4_gs: 15.0, home_R4_tgts_pg: 2.490566037735849, home_R4_recs_pg: 1.6037735849056605, home_R4_cyds_pg: 16.37735849056604, home_R4_ctd_pg: 0.1509433962264151, home_R4_c1d_pg: 0.7735849056603774, home_R4_csucc_ps: 90.825, home_R4_clng_ps: 45.75, home_R4_ratt_pg: 0.2641509433962264, home_R4_ryds_pg: 1.5471698113207548, home_R4_rtd_pg: 0.0, home_R4_r1d_pg: 0.1132075471698113, home_R4_rsucc_ps: 75.0, home_R4_rlng_ps: 20.5, home_R4_fmb_pg: 0.1132075471698113, home_R5_height: 193.0, home_R5_weight: 120.0, home_R5_age: 25.0, home_R5_av: 2.0, home_R5_games: 32.0, home_R5_gs: 18.0, home_R5_tgts_pg: 1.375, home_R5_recs_pg: 0.8125, home_R5_cyds_pg: 10.71875, home_R5_ctd_pg: 0.09375, home_R5_c1d_pg: 0.53125, home_R5_csucc_ps: 50.26666666666667, home_R5_clng_ps: 34.666666666666664, home_R5_ratt_pg: 0.0, home_R5_ryds_pg: 0.0, home_R5_rtd_pg: 0.0, home_R5_r1d_pg: 0.0, home_R5_rsucc_ps: 0.0, home_R5_rlng_ps: 0.0, home_R5_fmb_pg: 0.0, home_D1_height: 188.0, home_D1_weight: 117.0, home_D1_age: 29.0, home_D1_av: 25.0, home_D1_games: 78.0, home_D1_gs: 48.0, home_D1_int_pg: 0.0641025641025641, home_D1_pick6_pg: 0.0128205128205128, home_D1_pd_pg: 0.1923076923076923, home_D1_ff_pg: 0.1025641025641025, home_D1_ftd_pg: 0.0, home_D1_sk_pg: 0.3012820512820512, home_D1_qbh_pg: 0.5384615384615384, home_D1_sltk_pg: 2.0384615384615383, home_D1_astk_pg: 1.358974358974359, home_D1_tfl_pg: 0.3846153846153846, home_D1_sfty_pg: 0.0, home_D2_height: 198.0, home_D2_weight: 140.0, home_D2_age: 33.0, home_D2_av: 50.0, home_D2_games: 129.0, home_D2_gs: 117.0, home_D2_int_pg: 0.0077519379844961, home_D2_pick6_pg: 0.0, home_D2_pd_pg: 0.1317829457364341, home_D2_ff_pg: 0.0775193798449612, home_D2_ftd_pg: 0.0, home_D2_sk_pg: 0.2674418604651162, home_D2_qbh_pg: 0.4651162790697674, home_D2_sltk_pg: 2.2868217054263567, home_D2_astk_pg: 1.0465116279069768, home_D2_tfl_pg: 0.3488372093023256, home_D2_sfty_pg: 0.0, home_D3_height: 188.0, home_D3_weight: 147.0, home_D3_age: 32.0, home_D3_av: 91.0, home_D3_games: 156.0, home_D3_gs: 144.0, home_D3_int_pg: 0.0128205128205128, home_D3_pick6_pg: 0.0, home_D3_pd_pg: 0.1602564102564102, home_D3_ff_pg: 0.032051282051282, home_D3_ftd_pg: 0.0064102564102564, home_D3_sk_pg: 0.1217948717948717, home_D3_qbh_pg: 0.25, home_D3_sltk_pg: 2.3974358974358974, home_D3_astk_pg: 1.064102564102564, home_D3_tfl_pg: 0.2692307692307692, home_D3_sfty_pg: 0.0, home_D4_height: 196.0, home_D4_weight: 120.0, home_D4_age: 23.0, home_D4_av: 6.0, home_D4_games: 16.0, home_D4_gs: 14.0, home_D4_int_pg: 0.0, home_D4_pick6_pg: 0.0, home_D4_pd_pg: 0.25, home_D4_ff_pg: 0.1875, home_D4_ftd_pg: 0.0, home_D4_sk_pg: 0.375, home_D4_qbh_pg: 0.8125, home_D4_sltk_pg: 1.8125, home_D4_astk_pg: 1.5, home_D4_tfl_pg: 0.5625, home_D4_sfty_pg: 0.0, home_D5_height: 190.0, home_D5_weight: 117.0, home_D5_age: 23.0, home_D5_av: 7.0, home_D5_games: 16.0, home_D5_gs: 15.0, home_D5_int_pg: 0.0, home_D5_pick6_pg: 0.0, home_D5_pd_pg: 0.1875, home_D5_ff_pg: 0.0, home_D5_ftd_pg: 0.0625, home_D5_sk_pg: 0.25, home_D5_qbh_pg: 0.625, home_D5_sltk_pg: 3.125, home_D5_astk_pg: 1.25, home_D5_tfl_pg: 0.75, home_D5_sfty_pg: 0.0, home_D6_height: 188.0, home_D6_weight: 104.0, home_D6_age: 27.0, home_D6_av: 47.0, home_D6_games: 82.0, home_D6_gs: 80.0, home_D6_int_pg: 0.0365853658536585, home_D6_pick6_pg: 0.0, home_D6_pd_pg: 0.2195121951219512, home_D6_ff_pg: 0.1219512195121951, home_D6_ftd_pg: 0.0, home_D6_sk_pg: 0.0914634146341463, home_D6_qbh_pg: 0.2804878048780488, home_D6_sltk_pg: 5.743902439024391, home_D6_astk_pg: 3.024390243902439, home_D6_tfl_pg: 0.2926829268292683, home_D6_sfty_pg: 0.0, home_D7_height: 185.0, home_D7_weight: 94.0, home_D7_age: 27.0, home_D7_av: 23.0, home_D7_games: 66.0, home_D7_gs: 52.0, home_D7_int_pg: 0.2878787878787879, home_D7_pick6_pg: 0.0606060606060606, home_D7_pd_pg: 0.8636363636363636, home_D7_ff_pg: 0.0151515151515151, home_D7_ftd_pg: 0.0, home_D7_sk_pg: 0.0, home_D7_qbh_pg: 0.0, home_D7_sltk_pg: 2.8484848484848486, home_D7_astk_pg: 0.3939393939393939, home_D7_tfl_pg: 0.0909090909090909, home_D7_sfty_pg: 0.0, home_D8_height: 178.0, home_D8_weight: 92.0, home_D8_age: 24.0, home_D8_av: 3.0, home_D8_games: 12.0, home_D8_gs: 9.0, home_D8_int_pg: 0.25, home_D8_pick6_pg: 0.0833333333333333, home_D8_pd_pg: 0.75, home_D8_ff_pg: 0.1666666666666666, home_D8_ftd_pg: 0.0, home_D8_sk_pg: 0.0, home_D8_qbh_pg: 0.0, home_D8_sltk_pg: 3.4166666666666665, home_D8_astk_pg: 0.1666666666666666, home_D8_tfl_pg: 0.1666666666666666, home_D8_sfty_pg: 0.0, home_D9_height: 178.0, home_D9_weight: 88.0, home_D9_age: 26.0, home_D9_av: 22.0, home_D9_games: 52.0, home_D9_gs: 52.0, home_D9_int_pg: 0.2692307692307692, home_D9_pick6_pg: 0.0, home_D9_pd_pg: 0.8269230769230769, home_D9_ff_pg: 0.0769230769230769, home_D9_ftd_pg: 0.0, home_D9_sk_pg: 0.0192307692307692, home_D9_qbh_pg: 0.0192307692307692, home_D9_sltk_pg: 4.326923076923077, home_D9_astk_pg: 1.2307692307692308, home_D9_tfl_pg: 0.2115384615384615, home_D9_sfty_pg: 0.0, home_D10_height: 180.0, home_D10_weight: 90.0, home_D10_age: 30.0, home_D10_av: 22.0, home_D10_games: 106.0, home_D10_gs: 46.0, home_D10_int_pg: 0.0660377358490566, home_D10_pick6_pg: 0.0094339622641509, home_D10_pd_pg: 0.2547169811320754, home_D10_ff_pg: 0.0188679245283018, home_D10_ftd_pg: 0.0094339622641509, home_D10_sk_pg: 0.0188679245283018, home_D10_qbh_pg: 0.0377358490566037, home_D10_sltk_pg: 2.330188679245283, home_D10_astk_pg: 0.5660377358490566, home_D10_tfl_pg: 0.0471698113207547, home_D10_sfty_pg: 0.0, home_D11_height: 178.0, home_D11_weight: 88.0, home_D11_age: 27.0, home_D11_av: 15.0, home_D11_games: 64.0, home_D11_gs: 44.0, home_D11_int_pg: 0.125, home_D11_pick6_pg: 0.015625, home_D11_pd_pg: 0.53125, home_D11_ff_pg: 0.0625, home_D11_ftd_pg: 0.0, home_D11_sk_pg: 0.0, home_D11_qbh_pg: 0.03125, home_D11_sltk_pg: 3.578125, home_D11_astk_pg: 0.90625, home_D11_tfl_pg: 0.078125, home_D11_sfty_pg: 0.0, home_K_age: 29.0, home_K_av: 20.0, home_K_games: 116.0, home_K_fga_pg: 1.9396551724137927, home_K_fgm_pg: 1.646551724137931, home_K_fga_0-19_pg: 0.0086206896551724, home_K_fgm_0-19_pg: 0.0086206896551724, home_K_fga_20-29_pg: 0.603448275862069, home_K_fgm_20-29_pg: 0.5689655172413793, home_K_fga_30-39_pg: 0.7068965517241379, home_K_fgm_30-39_pg: 0.6206896551724138, home_K_fga_40-49_pg: 0.5, home_K_fgm_40-49_pg: 0.3534482758620689, home_K_fga_50+_pg: 0.0948275862068965, home_K_fgm_50+_pg: 0.0689655172413793, home_K_fglng_ps: 49.42857142857143, home_K_xpa_pg: 3.396551724137931, home_K_xpm_pg: 3.3879310344827585\n",
            "correct prediction\n",
            "Predicted: Home Win (100.00%), True: Home Win\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model.save('/content/sample_data/NFLmodel.keras')"
      ],
      "metadata": {
        "id": "SlX1CMGLFCx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('NFLmodel.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "02ScCL5OFqmU",
        "outputId": "324bf47d-9ffd-4012-a3b8-ef6d5f613af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed44ea2f-609b-4f72-9fd0-a5ae3276a790\", \"NFLmodel.keras\", 85867982)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}